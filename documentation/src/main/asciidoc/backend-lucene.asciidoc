[[backend-lucene]]
= Lucene backend

[[backend-lucene-configuration]]
== Basic configuration

In order to define a Lucene backend,
the `hibernate.search.backends.<backend name>.type` property must be set to `lucene`.

All other configuration properties are optional,
but the defaults might not suit everyone.
In particular, you might want to
<<backend-lucene-configuration-directory-local-filesystem-location,set the location of your indexes in the filesystem>>.

Other configuration properties are mentioned in the relevant parts of this documentation.
You can find a full reference of available properties in the Hibernate Search javadoc:

* link:{hibernateSearchJavadocUrl}/org/hibernate/search/backend/lucene/cfg/LuceneBackendSettings.html[org.hibernate.search.backend.lucene.cfg.LuceneBackendSettings].
* link:{hibernateSearchJavadocUrl}/org/hibernate/search/backend/lucene/cfg/LuceneIndexSettings.html[org.hibernate.search.backend.lucene.cfg.LuceneIndexSettings].

[[backend-lucene-configuration-directory]]
== Index storage (`Directory`)
// Search 5 anchors backward compatibility
[[search-configuration-directory]]

The component responsible for index storage in Lucene is the `org.apache.lucene.store.Directory`.
The implementation of the directory determines where the index will be stored:
on the filesystem, in the JVM's heap, ...

By default, the Lucene backend stores the indexes on the filesystem,
in the JVM's working directory.

The type of directory is set a the backend level:

// Search 5 anchors backward compatibility
[[example-configuring-directory-providers]]
[source]
----
hibernate.search.backends.<backend-name>.directory.type = local-filesystem
----

// Search 5 anchors backward compatibility
[[directory-provider-table]]
The following directory types are available:

* `local-filesystem`: Store the index on the local filesystem.
See <<backend-lucene-configuration-directory-local-filesystem>>
for details and configuration options.
* `local-heap`: Store the index in the local JVM heap.
*Local heap directories and all contained indexes are lost when the JVM shuts down.*
See <<backend-lucene-configuration-directory-local-heap>>
for details and configuration options.

[[backend-lucene-configuration-directory-local-filesystem]]
=== Local filesystem storage

The `local-filesystem` directory type will store each index in
a subdirectory of a configured filesystem directory.

[NOTE]
====
Local filesystem directories really are designed to be *local* to one server and one application.

In particular, they should not be shared between multiple Hibernate Search instances.
Even if network shares allow to share the raw content of indexes,
using the same index files from multiple Hibernate Search
would require more than that:
non-exclusive locking, routing of write requests from one node to another, ...
These additional features are simply not available on `local-filesystem` directories.

If you need to share indexes between multiple Hibernate Search instances,
the Elasticsearch backend will be a better choice.
Refer to <<architecture>> for more information.
====

[[backend-lucene-configuration-directory-local-filesystem-location]]
==== Index location

Each index is assigned a subdirectory under a root directory.

By default, the root directory is the JVM's working directory.
It can be configured at the backend level:

[source]
----
hibernate.search.backends.<backend-name>.directory.root = /path/to/my/root
----

For example, with the configuration above,
an entity of type `com.mycompany.Order` will be indexed in directory
`/path/to/my/root/com.mycompany.Order/`.
If that entity is explicitly assigned the index name "orders"
(see `@Indexed(index = ...)` in <<mapper-orm-entityindexmapping>>),
it will instead be indexed in directory
`/path/to/my/root/orders/`.

==== Filesystem access strategy

The default strategy for accessing the filesystem is determined automatically
based on the operating system and architecture.
It should work well in most situations.

For situations where a different filesystem access strategy is needed,
Hibernate Search exposes a configuration property at the backend level:

[source]
----
hibernate.search.backends.<backend-name>.directory.filesystem_access.strategy = auto (default)
----

Allowed values are:

* `auto` (default): lets Lucene select the most appropriate implementation
based on the operating system and architecture.
* `simple`: a straightforward strategy based on `Files.newByteChannel`.
See `org.apache.lucene.store.SimpleFSDirectory`.
* `mmap`: uses `mmap` for reading, and `FSDirectory.FSIndexOutput` for writing.
See `org.apache.lucene.store.MMapDirectory`.
* `nio`: uses ``java.nio.channels.FileChannel``'s positional read for concurrent reading,
and `FSDirectory.FSIndexOutput` for writing.
See `org.apache.lucene.store.NIOFSDirectory`.

[NOTE]
====
Make sure to refer to Javadocs of these `Directory`
implementations before changing this setting.
Implementations offering better performance
also bring issues of their own.
====

==== Other configuration options

The `local-filesystem` directory also allows configuring a
<<backend-lucene-configuration-directory-locking-strategy,locking strategy>>.

[[backend-lucene-configuration-directory-local-heap]]
=== Local heap storage

The `local-heap` directory type will store indexes in the local JVM's heap.

As a result, indexes contained in a `local-heap` directory are *lost when the JVM shuts down*.

This directory type is only provided for use in *testing configurations*
with *small indexes* and *low concurrency*,
where it could slightly improve performance.
In setups requiring larger indexes and/or high concurrency,
a <<backend-lucene-configuration-directory-local-filesystem,filesystem-based directory>>
will achieve better performance.

The `local-heap` directory does not offer any specific option
beyond the <<backend-lucene-configuration-directory-locking-strategy,locking strategy>>.

[[backend-lucene-configuration-directory-locking-strategy]]
=== Locking strategy
// Search 5 anchors backward compatibility
[[search-configuration-directory-lockfactories]]

In order to write to an index, Lucene needs to acquire a lock to ensure no other application instance
writes to the same index concurrently.
Each directory type comes with a default locking strategy that should work well enough in most situations.

For those (very) rare situations where a different locking strategy is needed,
Hibernate Search exposes a configuration property at the backend level:

[source]
----
hibernate.search.backends.<backend-name>.directory.locking.strategy = native-filesystem
----

The following strategies are available:

* `simple-filesystem`:
Locks the index by creating a marker file and checking it before write operations.
This implementation is very simple and based Java's File API.
If for some reason an application ends abruptly,
the marker file will stay on the filesystem and will need to be removed manually.
+
This strategy is only available for filesystem-based directories.
+
See `org.apache.lucene.store.SimpleFSLockFactory`.
* `native-filesystem`:
Similarly to `simple-filesystem`, locks the index by creating a marker file,
but using native OS file locks instead of Java's File API,
so that locks will be cleaned up if the application ends abruptly.
+
This is the default strategy for the `local-filesystem` directory type.
+
This implementation has known problems with NFS: it should be avoided on network shares.
+
This strategy is only available for filesystem-based directories.
+
See `org.apache.lucene.store.NativeFSLockFactory`.
* `single-instance`:
Locks using a Java object held in the JVM's heap.
Since the lock is only accessible by the same JVM,
this strategy will only work properly when it is known
that only a single application will ever try to accesses the indexes.
+
This is the default strategy for the `local-heap` directory type.
+
See `org.apache.lucene.store.SingleInstanceLockFactory`.
* `none`:
Does not use any lock.
Concurrent writes from another application will result in index corruption.
Test your application carefully and make sure you know what it means.
+
See `org.apache.lucene.store.NoLockFactory`.

[[backend-lucene-configuration-sharding]]
== Sharding

include::components/sharding-intro-note.asciidoc[]

In the Lucene backend, sharding is disabled by default,
but can be enabled by selecting a sharding strategy at the index level.
Multiple strategies are available:

`hash`::
+
[source]
----
hibernate.search.backends.<backend name>.indexes.<index name>.sharding.strategy = hash
hibernate.search.backends.<backend name>.indexes.<index name>.sharding.number_of_shards = 2 (no default)
# OR
hibernate.search.backends.<backend name>.index_defaults.sharding.strategy = hash
hibernate.search.backends.<backend name>.index_defaults.sharding.number_of_shards = 2 (no default)
----
+
The `hash` strategy requires to set a number of shards through the `number_of_shards` property.
+
This strategy will set up an explicitly configured number of shards,
numbered from 0 to the chosen number minus one
(e.g. for 2 shards, there will be shard "0" and shard "1").
+
When routing, the routing key will be hashed to assign it to a shard.
If the routing key is null, the document ID will be used instead.
+
This strategy is suitable when there is no explicit routing key
<<mapper-orm-bridge-routingkeybridge,configured in the mapping>>,
or when the routing key has a large number of possible values that need
to be brought down to a smaller number (e.g. "all integers").

`explicit`::
+
[source]
----
hibernate.search.backends.<backend name>.indexes.<index name>.sharding.strategy = explicit
hibernate.search.backends.<backend name>.indexes.<index name>.sharding.shard_identifiers = fr,en,de (no default)
# OR
hibernate.search.backends.<backend name>.index_defaults.sharding.strategy = explicit
hibernate.search.backends.<backend name>.index_defaults.sharding.shard_identifiers = fr,en,de (no default)
----
+
The `explicit` strategy requires to set a list of shard identifiers through the `shard_identifiers` property.
The identifiers must be provided as a String containing multiple shard identifiers separated by commas,
or a `Collection<String>` containing shard identifiers.
A shard identifier can be any string.
+
This strategy will set up one shard per configured shard identifier.
+
When routing, the routing key will be validated to make sure it matches a shard identifier exactly.
If it does, the document will be routed to that shard.
If it does not, an exception will be thrown.
The routing key cannot be null, and the document ID will be ignored.
+
This strategy is suitable when there an explicit routing key
<<mapper-orm-bridge-routingkeybridge,configured in the mapping>>,
and that routing key has a limited number of possible values that are known before starting the application.

== Index format compatibility

While Hibernate Search strives to offer a backwards compatible API,
making it easy to port your application to newer versions,
it still delegates to Apache Lucene to handle the index writing and searching.
This creates a dependency to the Lucene index format.
The Lucene developers of course attempt to keep a stable index format,
but sometimes a change in the format can not be avoided.
In those cases you either have to re-index all your data or use an index upgrade tool.
Sometimes, Lucene is also able to read the old format so you don't need to take specific actions
(besides making backup of your index).

While an index format incompatibility is a rare event,
it can happen more often that Lucene's Analyzer implementations might slightly change its behavior.
This can lead to some documents not matching anymore, even though they used to.

To avoid this analyzer incompatibility,
Hibernate Search allows to configure to which version of Lucene
the analyzers and other Lucene classes should conform their behavior.

This configuration property is set at the backend level:

[source]
----
hibernate.search.backends.<backend-name>.lucene_version = LUCENE_8_1_1
----

Depending on the specific version of Lucene you're using,
you might have different options available:
see `org.apache.lucene.util.Version` contained in `lucene-core.jar`
for a list of allowed values.

When this option is not set, Hibernate Search will instruct Lucene to use the latest version,
which is usually the best option for new projects.
Still, it's recommended to define the version you're using explicitly in the configuration,
so that when you happen to upgrade, Lucene the analyzers will not change behavior.
You can then choose to update this value at a later time,
for example when you have the chance to rebuild the index from scratch.

[NOTE]
====
The setting will be applied consistently when using Hibernate Search APIs,
but if you are also making use of Lucene bypassing Hibernate Search
(for example when instantiating an Analyzer yourself),
make sure to use the same value.
====

[[backend-lucene-schema]]
== Schema

Lucene does not really have a concept of centralized schema to specify the data type and capabilities of each field,
but Hibernate Search maintains such a schema in memory,
in order to remember which predicates/projections/sorts can be applied to each field.

For the most part, the schema is inferred from
<<mapper-orm-mapping,the mapping configured through Hibernate Search's mapping APIs>>,
which are generic and independent from Elasticsearch.

Aspects that are specific to the Lucene backend are explained in this section.

[[backend-lucene-field-types]]
=== Field types

[[backend-lucene-field-types-available]]
==== Available field types

[NOTE]
====
Some types are not supported directly by the Elasticsearch backend,
but will work anyway because they are "bridged" by the mapper.
For example a `java.util.Date` in your entity model is "bridged" to `java.time.Instant`,
which is supported by the Elasticsearch backend.
See <<mapper-orm-directfieldmapping-supported-types>> for more information.
====

[NOTE]
====
Field types that are not in this list can still be used with a little bit more work:

* If a property in the entity model has an unsupported type,
but can be converted to a supported type, you will need a bridge.
See <<mapper-orm-bridge>>.
* If you need an index field with a specific type that is not supported by Hibernate Search,
you will need a bridge that defines a native field type.
See <<backend-lucene-field-types-extension>>.
====

[cols="l,1",options="header"]
.Field types supported by the Lucene backend
|====
|Field type|Limitations
|java.lang.String|-
|java.lang.Byte|-
|java.lang.Short|-
|java.lang.Integer|-
|java.lang.Long|-
|java.lang.Double|-
|java.lang.Float|-
|java.lang.Boolean|-
|java.math.BigDecimal|-
|java.math.BigInteger|-
|java.time.Instant|<<backend-lucene-field-types-date-time>>
|java.time.LocalDate|<<backend-lucene-field-types-date-time>>
|java.time.LocalTime|<<backend-lucene-field-types-date-time>>
|java.time.LocalDateTime|<<backend-lucene-field-types-date-time>>
|java.time.ZonedDateTime|<<backend-lucene-field-types-date-time>>
|java.time.OffsetDateTime|<<backend-lucene-field-types-date-time>>
|java.time.OffsetTime|<<backend-lucene-field-types-date-time>>
|java.time.Year|<<backend-lucene-field-types-date-time>>
|java.time.YearMonth|<<backend-lucene-field-types-date-time>>
|java.time.MonthDay|-
|org.hibernate.search.engine.spatial.GeoPoint|-
|====

[[backend-lucene-field-types-date-time,Lower range/resolution]]
[NOTE]
.Range and resolution of date/time fields
====
Date/time types do not support the whole range of years that can be represented in `java.time` types:

* `java.time` can represent years ranging from `-999.999.999` to `999.999.999`.
* The Lucene backend supports dates ranging from year `-292.275.054` to year `292.278.993`.

Values that are out of range will trigger indexing failures.

Resolution for time types is also lower:

* `java.time` supports nanosecond-resolution.
* The Lucene backend supports millisecond-resolution.

Precision beyond the millisecond will be lost when indexing.
====

[[backend-lucene-field-types-extension]]
==== Index field type DSL extensions

Not all Lucene field types have built-in support in Hibernate Search.
Unsupported field types can still be used, however,
by taking advantage of the "native" field type.
Using this field type, Lucene `IndexableField` instances can be created directly,
giving access to everything Lucene can offer.

Below is an example of how to use the Lucene "native" type.

.Using the Lucene "native" type
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/backend/lucene/type/asnative/PageRankValueBinder.java[tags=include]
----
<1> Define a <<mapper-orm-bridge,custom binder>> and its bridge.
The "native" type can only be used from a binder,
it cannot be used directly with annotation mapping.
Here we're defining a <<mapper-orm-bridge-valuebridge,value binder>>,
but a <<mapper-orm-bridge-typebridge,type binder>>,
or a <<mapper-orm-bridge-propertybridge,property binder>>
would work as well.
<2> Get the context's type factory.
<3> Apply the Lucene extension to the type factory.
<4> Call `asNative` to start defining a native type.
<5> Define the field value type.
<6> Define the `LuceneFieldContributor`.
The contributor will be called upon indexing to add as many fields as necessary to the document.
All fields must be named after the `absoluteFieldPath` passed to the contributor.
<7> Optionally, if projections are necessary, define the `LuceneFieldValueExtractor`.
The extractor will be called upon projecting to extract the projected value from a *single* stored field.
<8> The value bridge is free to apply a preliminary conversion
before passing the value to Hibernate Search, which will pass it along to the `LuceneFieldContributor`.

[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/backend/lucene/type/asnative/WebPage.java[tags=include,!getters-setters]
----
<1> Map the property to an index field.
Note that value bridges using a non-standard field type (such as Lucene's "native" type)
must be mapped using the `@NonStandardField` annotation:
other annotations such as `@GenericField` will fail.
<2> Instruct Hibernate Search to use our custom value binder.
====

[[backend-lucene-multi-tenancy]]
=== Multi-tenancy

Multi-tenancy is supported and handled transparently,
according to the tenant ID defined in the current session:

* documents will be indexed with the appropriate values, allowing later filtering;
* queries will filter results appropriately.

However, a strategy must be selected in order to enable multi-tenancy.

The multi-tenancy strategy is set a the backend level:

[source]
----
hibernate.search.backends.<backend name>.multi_tenancy.strategy = none (default)
----

See the following subsections for details about available strategies.

[[backend-lucene-multi-tenancy-none]]
==== `none`: single-tenancy

The `none` strategy (the default) disables multi-tenancy completely.

Attempting to set a tenant ID will lead to a failure when indexing.

[[backend-lucene-multi-tenancy-discriminator]]
==== `discriminator`: type name mapping using the index name

With the `discriminator` strategy,
all documents from all tenants are stored in the same index.

When indexing, a discriminator field holding the tenant ID is populated transparently for each document.

When searching, a filter targeting the tenant ID field is added transparently to the search query
to only return search hits for the current tenant.

[[backend-lucene-analysis]]
== Analysis

<<concepts-analysis,Analysis>> is the text processing performed by analyzers,
both when indexing (document processing)
and when searching (query processing).

To configure analysis in a Lucene backend, you will need to:

* Define a class that implements the `org.hibernate.search.backend.lucene.analysis.LuceneAnalysisConfigurer` interface.
* Configure the backend to use that implementation by setting the configuration property
`hibernate.search.backends.<backend name>.analysis.configurer`
to a <<configuration-property-types,bean reference>> pointing to the implementation.

Hibernate Search will call the `configure` method of this implementation on startup,
and the configurer will be able to take advantage of a DSL to define analyzers:

.Implementing and using an analysis configurer with the Lucene backend
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/analysis/MyLuceneAnalysisConfigurer.java[tags=include]
----
<1> Define a custom analyzer named "english", because it will be used to analyze English text such as book titles.
<2> Set the tokenizer to a standard tokenizer: components are referenced by their factory class.
<3> Set the char filters. Char filters are applied in the order they are given, before the tokenizer.
<4> Set the token filters. Token filters are applied in the order they are given, after the tokenizer.
<5> Set the value of a parameter for the last added char filter/tokenizer/token filter.
<6> Normalizers are defined in a similar way, the only difference being that they cannot use a tokenizer.
<7> Multiple analyzers/normalizers can be defined in the same configurer.

[source, XML, indent=0, subs="+callouts"]
----
include::{resourcesdir}/analysis/lucene-simple.properties[]
----
<1> Assign the configurer to the backend `myBackend` using a Hibernate Search configuration property.
====

It is also possible to assign a name to a built-in analyzer,
or a custom analyzer implementation:

.Naming an analyzer instance in the Lucene backend
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/analysis/AdvancedLuceneAnalysisConfigurer.java[tags=instance]
----
====

[TIP]
====
To know which analyzers, character filters, tokenizers and token filters are available,
either browse the Lucene Javadoc or read the corresponding section on the
link:http://wiki.apache.org/solr/AnalyzersTokenizersTokenFilters[Solr Wiki]
(you don't need Solr to use these analyzers,
it's just that there is no documentation page for Lucene proper).
====
