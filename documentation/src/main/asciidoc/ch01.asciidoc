[[getting-started]]
== Getting started

Welcome to Hibernate Search. The following chapter will guide you through the initial steps required
to integrate Hibernate Search into an existing Hibernate enabled application. In case you are a
Hibernate new timer we recommend you start link:$$http://hibernate.org/quick-start.html$$[here].


=== System Requirements

.System requirements

|===============
|Java Runtime|A JDK or JRE version _6_ or greater. You
            can download a Java Runtime for Windows/Linux/Solaris link:$$http://www.oracle.com/technetwork/java/javase/downloads/index.html$$[here].
|Hibernate Search|+hibernate-search-{version}.jar+ and all
            runtime dependencies. You can get the jar artifacts either from
            the +dist/lib+ directory of the link:$$http://sourceforge.net/projects/hibernate/files/hibernate-search/$$[Hibernate Search distribution] or you can download them from the
            link:$$http://repository.jboss.org/nexus/content/groups/public-jboss/ $$[JBoss maven repository].
|Hibernate Core|You will need
            +hibernate-core-{hibernateVersion}.jar+ and its
            transitive dependencies (either from the link:$$http://sourceforge.net/projects/hibernate/files/hibernate3/$$[distribution bundle] or the maven repository).
|JPA 2.1|Even though Hibernate Search can be used without JPA
            annotations the following instructions will use them for basic
            entity configuration (__@Entity, @Id, @OneToMany,...__). This part of the configuration could
            also be expressed in XML or code. Hibernate Search, however, has also its own set of annotations (__@Indexed, @DocumentId, @Field,...__) for which there exists so far no XML based alternative; a better option is the <<hsearch-mapping-programmaticapi>>.

|===============

=== Using Maven

The Hibernate Search artifacts can be found in Maven's central repository but are released first in the link:$$http://repository.jboss.org/nexus/content/groups/public-jboss/ $$[JBoss maven repository]. So it's not a requirement but we recommend to add this repository to your _settings.xml file_ (see also link:$$http://community.jboss.org/wiki/MavenGettingStarted-Users$$[Maven Getting Started] for more details).

All you have to add to your pom.xml is:

.Maven artifact identifier for Hibernate Search
====
[source, XML]
[subs="verbatim,attributes"]
----
<dependency>
   <groupId>org.hibernate</groupId>
   <artifactId>hibernate-search</artifactId>
   <version>{version}</version>
</dependency>
----
====

.Optional Maven dependencies for Hibernate Search
====
[source, XML]
[subs="verbatim,attributes"]
----
<dependency>
<!-- If using JPA (2), add: -->
<dependency>
   <groupId>org.hibernate</groupId>
   <artifactId>hibernate-entitymanager</artifactId>
   <version>{hibernateVersion}</version>
</dependency>
<!-- Infinispan integration: -->
<dependency>
   <groupId>org.hibernate</groupId>
   <artifactId>hibernate-search-infinispan</artifactId>
   <version>{version}</version>
</dependency>
----
====

Only the _hibernate-search_ dependency is mandatory.__hibernate-entitymanager__ is only required if
you want to use Hibernate Search in conjunction with JPA.

To use _hibernate-search-infinispan_, adding the JBoss Maven repository is mandatory, because it
contains the needed Infinispan dependencies which are currently not mirrored by +central+.


=== Configuration

Once you have downloaded and added all required dependencies to your application you have to add a
couple of properties to your hibernate configuration file. If you are using Hibernate directly this
can be done in +hibernate.properties+ or +hibernate.cfg.xml+. If you are using Hibernate via JPA you
can also add the properties to +persistence.xml+. The good news is that for standard use most
properties offer a sensible default. An example _persistence.xml_ configuration could look like
this:

.Basic configuration options to be added to +_hibernateproperties_+, +_hibernatecfgxml_+ or
._persistencexml_

====
[source, XML]
----
...
<property name="hibernate.search.default.directory_provider"
          value="filesystem"/>

<property name="hibernate.search.default.indexBase"
          value="/var/lucene/indexes"/>
...
----
====

First you have to tell Hibernate Search which DirectoryProvider to use. This can be achieved by
setting the +$$hibernate.search.default.directory_provider$$+ property. Apache Lucene has the notion
of a +Directory+ to store the index files. Hibernate Search handles the initialization and
configuration of a Lucene +Directory+ instance via a +DirectoryProvider+. In this tutorial we will
use a a directory provider storing the index in the file system. This will give us the ability to
physically inspect the Lucene indexes created by Hibernate Search (eg via
link:$$http://code.google.com/p/luke/$$[Luke]). Once you have a working configuration you can start
experimenting with other directory providers (see <<search-configuration-directory>>). Next to the
directory provider you also have to specify the default base directory for all indexes via
+hibernate.search.default.indexBase+.

Lets assume that your application contains the Hibernate managed classes example.Book and
example.Author and you want to add free text search capabilities to your application in order to
search the books contained in your database.

.Example entities Book and Author before adding Hibernate Search specific annotations
====
[source, JAVA]
----
package example;
...
@Entity
public class Book {

  @Id
  @GeneratedValue
  private Integer id;

  private String title;

  private String subtitle;

  @ManyToMany
  private Set<Author> authors = new HashSet<Author>();

  private Date publicationDate;

  public Book() {}

  // standard getters/setters follow here
  ...
}
----


[source, JAVA]
----
package example;
...
@Entity
public class Author {

  @Id
  @GeneratedValue
  private Integer id;

  private String name;

  public Author() {}

  // standard getters/setters follow here
  ...
}
----
====

To achieve this you have to add a few annotations to the Book and Author class. The first annotation
+@Indexed+ marks Book as indexable. By design Hibernate Search needs to store an untokenized id in
the index to ensure index unicity for a given entity. +@DocumentId+ marks the property to use for
this purpose and is in most cases the same as the database primary key. The +@DocumentId+ annotation
is optional in the case where an @Id annotation exists.

Next you have to mark the fields you want to make searchable. Let's start with +title+ and
+subtitle+ and annotate both with +@Field+. The parameter +index=Index.YES+ will ensure that the
text will be indexed, while +analyze=Analyze.YES+ ensures that the text will be analyzed using the
default Lucene analyzer. Usually, analyzing means chunking a sentence into individual words and
potentially excluding common words like +$$'a'$$+ or '++the++'. We will talk more about analyzers a
little later on. The third parameter we specify within ++@Field++,++ store=Store.NO++, ensures that
the actual data will not be stored in the index. Whether this data is stored in the index or not has
nothing to do with the ability to search for it. From Lucene's perspective it is not necessary to
keep the data once the index is created. The benefit of storing it is the ability to retrieve it via
projections ( see <<projections>>).

Without projections, Hibernate Search will per default execute a Lucene query in order to find the
database identifiers of the entities matching the query criteria and use these identifiers to
retrieve managed objects from the database. The decision for or against projection has to be made on
a case to case basis. The default behavior is recommended since it returns managed objects whereas
projections only return object arrays.

Note that +index=Index.YES+, +analyze=Analyze.YES+ and +store=Store.NO+ are the default values for
these parameters and could be omitted.

After this short look under the hood let's go back to annotating the Book class. Another annotation
we have not yet discussed is +@DateBridge+. This annotation is one of the built-in field bridges in
Hibernate Search. The Lucene index is purely string based. For this reason Hibernate Search must
convert the data types of the indexed fields to strings and vice versa. A range of predefined
bridges are provided, including the DateBridge which will convert a java.util.Date into a String
with the specified resolution. For more details see <<search-mapping-bridge>>.

This leaves us with ++@IndexedEmbedded. ++This annotation is used to index associated entities
(++@ManyToMany++, ++@\*ToOne++, ++@Embedded++ and ++@ElementCollection++) as part of the owning
entity. This is needed since a Lucene index document is a flat data structure which does not know
anything about object relations. To ensure that the authors' name will be searchable you have to
make sure that the names are indexed as part of the book itself. On top of ++@IndexedEmbedded++ you
will also have to mark all fields of the associated entity you want to have included in the index
with ++@Indexed++. For more details see <<search-mapping-associated>>.

These settings should be sufficient for now. For more details on entity mapping refer to
<<search-mapping-entity>>.

.Example entities after adding Hibernate Search annotations
====
[source, JAVA]
----
package example;
...
@Entity
@Indexed
public class Book {

  @Id
  @GeneratedValue
  private Integer id;

  @Field(index=Index.YES, analyze=Analyze.YES, store=Store.NO)
  private String title;

  @Field(index=Index.YES, analyze=Analyze.YES, store=Store.NO)
  private String subtitle;

  @Field(index = Index.YES, analyze=Analyze.NO, store = Store.YES)
  @DateBridge(resolution = Resolution.DAY)
  private Date publicationDate;

  @IndexedEmbedded
  @ManyToMany
  private Set<Author> authors = new HashSet<Author>();
  public Book() {
  }

  // standard getters/setters follow here
  ...
}
----

[source, JAVA]
----
@Entity
public class Author {

  @Id
  @GeneratedValue
  private Integer id;

  @Field
  private String name;

  public Author() {
  }

  // standard getters/setters follow here
  ...
}
====


=== Indexing

Hibernate Search will transparently index every entity persisted, updated or removed through
Hibernate Core. However, you have to create an initial Lucene index for the data already present in
your database. Once you have added the above properties and annotations it is time to trigger an
initial batch index of your books. You can achieve this by using one of the following code snippets
(see also <<search-batchindex>>):

.Using Hibernate Session to index data
====
[source, JAVA]
----
FullTextSession fullTextSession = Search.getFullTextSession(session);
fullTextSession.createIndexer().startAndWait();
----
====

.Using JPA to index data
====
[source, JAVA]
----
EntityManager em = entityManagerFactory.createEntityManager();
FullTextEntityManager fullTextEntityManager = Search.getFullTextEntityManager(em);
fullTextEntityManager.createIndexer().startAndWait();
----
====

After executing the above code, you should be able to see a Lucene index under
+/var/lucene/indexes/example.Book+. Go ahead an inspect this index with
link:$$http://code.google.com/p/luke/$$[Luke]. It will help you to understand how Hibernate Search
works.

=== Searching

Now it is time to execute a first search. The general approach is to create a Lucene query, either
via the Lucene API (<<search-query-lucene-api>>) or via the Hibernate Search query DSL
(<<search-query-querydsl>>), and then wrap this query into a org.hibernate.Query in order to get all the
functionality one is used to from the Hibernate API. The following code will prepare a query against
the indexed fields, execute it and return a list of Books.

.Using Hibernate Session to create and execute a search
====
[source, JAVA]
----
FullTextSession fullTextSession = Search.getFullTextSession(session);
Transaction tx = fullTextSession.beginTransaction();

// create native Lucene query unsing the query DSL
// alternatively you can write the Lucene query using the Lucene query parser
// or the Lucene programmatic API. The Hibernate Search DSL is recommended though
QueryBuilder qb = fullTextSession.getSearchFactory()
  .buildQueryBuilder().forEntity(Book.class).get();
org.apache.lucene.search.Query query = qb
  .keyword()
  .onFields("title", "subtitle", "authors.name")
  .matching("Java rocks!")
  .createQuery();

// wrap Lucene query in a org.hibernate.Query
org.hibernate.Query hibQuery =
    fullTextSession.createFullTextQuery(query, Book.class);

// execute search
List result = hibQuery.list();

tx.commit();
session.close();
----
====

.Using JPA to create and execute a search
====
[source, JAVA]
----
EntityManager em = entityManagerFactory.createEntityManager();
FullTextEntityManager fullTextEntityManager =
    org.hibernate.search.jpa.Search.getFullTextEntityManager(em);
em.getTransaction().begin();

// create native Lucene query unsing the query DSL
// alternatively you can write the Lucene query using the Lucene query parser
// or the Lucene programmatic API. The Hibernate Search DSL is recommended though
QueryBuilder qb = fullTextEntityManager.getSearchFactory()
    .buildQueryBuilder().forEntity(Book.class).get();
org.apache.lucene.search.Query query = qb
  .keyword()
  .onFields("title", "subtitle", "authors.name")
  .matching("Java rocks!")
  .createQuery();

// wrap Lucene query in a javax.persistence.Query
javax.persistence.Query persistenceQuery =
    fullTextEntityManager.createFullTextQuery(query, Book.class);

// execute search
List result = persistenceQuery.getResultList();

em.getTransaction().commit();
em.close();
----
====


=== Analyzer

Let's make things a little more interesting now. Assume that one of your indexed book entities has
the title "Refactoring: Improving the Design of Existing Code" and you want to get hits for all of
the following queries: "refactor", "refactors", "refactored" and "refactoring". In Lucene this can
be achieved by choosing an analyzer class which applies word stemming during the indexing *as well
as* the search process. Hibernate Search offers several ways to configure the analyzer to be used
(see <<analyzer>>):


* Setting the +hibernate.search.analyzer+ property in the configuration file. 
The specified class will then be the default analyzer.
* Setting the ++@Analyzer++ annotation at the entity level.
* Setting the +@++Analyzer+++ annotation at the field level.

When using the +@Analyzer+ annotation one can either specify the fully qualified classname of the
analyzer to use or one can refer to an analyzer definition defined by the +@AnalyzerDef+ annotation.
In the latter case the analyzer framework with its factories approach is utilized. To find out more
about the factory classes available you can either browse the Lucene JavaDoc or read the
corresponding section on the
link:$$http://wiki.apache.org/solr/AnalyzersTokenizersTokenFilters$$[Solr Wiki].

[NOTE]
====
Why the reference to the Apache Solr wiki?

Apache Solr was historically an indepedent sister project of Apache Lucene and the analyzer factory
framework was originally developed within it. By now, Lucene and Solr have merged, but the
documentation for these additional analyzers can still be found in the Solr Wiki. You might find
other documentation referring to the "Solr Analyzer Framework" - just remember you don't need to
depend on Apache Solr anymore to use it. The required classes are part of the core Lucene
distribution.
====

In the example below a StandardTokenizerFactory is used followed by two filter factories,
LowerCaseFilterFactory and SnowballPorterFilterFactory. The standard tokenizer splits words at
punctuation characters and hyphens while keeping email addresses and internet hostnames intact. It
is a good general purpose tokenizer. The lowercase filter lowercases the letters in each token
whereas the snowball filter finally applies language specific stemming.

Generally, when using the Analyzer Framework you have to start with a tokenizer followed by an
arbitrary number of filters.


.Using +@AnalyzerDef+ and the Analyzer Framework to define and use an analyzer
====
[source, JAVA]
----
@Entity
@Indexed
@AnalyzerDef(name = "customanalyzer",
  tokenizer = @TokenizerDef(factory = StandardTokenizerFactory.class),
  filters = {
    @TokenFilterDef(factory = LowerCaseFilterFactory.class),
    @TokenFilterDef(factory = SnowballPorterFilterFactory.class, params = {
      @Parameter(name = "language", value = "English")
    })
  })
public class Book {

  @Id
  @GeneratedValue
  @DocumentId
  private Integer id;

  @Field
  @Analyzer(definition = "customanalyzer")
  private String title;

  @Field
  @Analyzer(definition = "customanalyzer")
  private String subtitle;

  @IndexedEmbedded
  @ManyToMany
  private Set<Author> authors = new HashSet<Author>();

  @Field(index = Index.YES, analyze = Analyze.NO, store = Store.YES)
  @DateBridge(resolution = Resolution.DAY)
  private Date publicationDate;

  public Book() {
  }

  // standard getters/setters follow here
  ...
}
====

Using @AnalyzerDef only defines an Analyzer, you still have to apply it to entities and or
properties using @Analyzer. Like in the above example the +customanalyzer+ is defined but not
applied on the entity: it's applied on the +title+ and +subtitle+ properties only. An analyzer
definition is global, so you can define it on any entity and reuse the definition on other entities.

=== What's next

The above paragraphs helped you getting an overview of Hibernate Search. The next step after this
tutorial is to get more familiar with the overall architecture of Hibernate Search
(<<search-architecture>>) and explore the basic features in more detail. Two topics which were only briefly
touched in this tutorial were analyzer configuration (<<analyzer>>) and field bridges
(<<search-mapping-bridge>>). Both are important features required for more fine-grained indexing. More
advanced topics cover clustering (<<jms-backend>>, <<infinispan-directories>>) and large index
handling (<<advanced-features-sharding>>).
