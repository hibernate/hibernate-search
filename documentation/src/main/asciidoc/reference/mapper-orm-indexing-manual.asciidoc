[[mapper-orm-indexing-manual]]
= [[manual-index-changes]] Reindexing large amounts of data manually with Hibernate ORM

include::components/mapper-orm-only-note.asciidoc[]

[[mapper-orm-indexing-manual-basics]]
== [[search-batchindex]] Basics

While <<indexing-automatic,automatic indexing>> and
the <<indexing-massindexer,`MassIndexer`>>
or <<mapper-orm-indexing-jsr352,the mass indexing job>>
should take care of most needs,
it is sometimes necessary to control indexing manually,
for example to reindex just a few entity instances
that were affected by changes to the database that automatic indexing cannot detect,
such as JPQL/SQL `insert`, `update` or `delete` queries.

To address these use cases, Hibernate Search exposes several APIs
explained if the following sections.

As with everything in Hibernate Search,
these APIs only affect the Hibernate Search indexes:
they do not write anything to the database.

[[mapper-orm-indexing-manual-indexingplan-process-execute]]
== [[search-batchindex-flushtoindexes]] Controlling entity reads and index writes with `SearchIndexingPlan`

A fairly common use case when manipulating large datasets with JPA
is the link:{hibernateDocUrl}#batch-session-batch-insert[periodic "flush-clear" pattern],
where a loop reads or writes entities for every iteration
and flushes then clears the session every `n` iterations.
This patterns allows processing a large number of entities
while keeping the memory footprint reasonably low.

Below is an example of this pattern to persist a large number of entities
when not using Hibernate Search.

.A batch process with JPA
====
[source, JAVA, indent=0]
----
include::{sourcedir}/org/hibernate/search/documentation/mapper/orm/indexing/HibernateOrmManualIndexingIT.java[tags=persist-automatic-indexing-periodic-flush-clear]
----
<1> Execute a loop for a large number of elements, inside a transaction.
<2> For every iteration of the loop, instantiate a new entity and persist it.
<3> Every `BATCH_SIZE` iterations of the loop, `flush` the entity manager to send the changes to the database-side buffer.
<4> After a `flush`, `clear` the ORM session to release some memory.
====

With Hibernate Search 6 (on contrary to Hibernate Search 5 and earlier),
this pattern will work as expected:

* <<coordination-none,with coordination disabled>> (the default),
documents will be built on flushes, and sent to the index upon transaction commit.
* <<coordination-outbox-polling,with outbox-polling coordination>>,
entity change events will be persisted on flushes, and committed along with the rest of the changes upon transaction commit.

However, each `flush` call will potentially add data to an internal buffer,
which for large volumes of data may lead to an `OutOfMemoryException`,
depending on the JVM heap size,
the <<coordination,coordination strategy>>
and the complexity and number of documents.

If you run into memory issues,
the first solution is to break down the batch process
into multiple transactions, each handling a smaller number of elements:
the internal document buffer will be cleared after each transaction.

See below for an example.

[IMPORTANT]
====
With this pattern, if one transaction fails,
part of the data will already be in the database and in indexes,
with no way to roll back the changes.

However, the indexes will be consistent with the database,
and it will be possible to (manually) restart the process
from the last transaction that failed.
====

.A batch process with Hibernate Search using multiple transactions
====
[source, JAVA, indent=0]
----
include::{sourcedir}/org/hibernate/search/documentation/mapper/orm/indexing/HibernateOrmManualIndexingIT.java[tags=persist-automatic-indexing-multiple-transactions]
----
<1> Add an outer loop that creates one transaction per iteration.
<2> Begin the transaction at the beginning of each iteration of the outer loop.
<3> Only handle a limited number of elements per transaction.
<4> For every iteration of the loop, instantiate a new entity and persist it.
Note we're relying on automatic indexing to index the entity,
but this would work just as well if automatic indexing was disabled,
only requiring an extra call to index the entity.
See <<indexing-plan>>.
<5> Commit the transaction at the end of each iteration of the outer loop.
The entities will be flushed and indexed automatically.
====

[NOTE]
====
The multi-transaction solution
and the original `flush()`/`clear()` loop pattern can be combined,
breaking down the process in multiple medium-sized transactions,
and periodically calling `flush`/`clear` inside each transaction.

This combined solution is the most flexible,
hence the most suitable if you want to fine-tune your batch process.
====

If breaking down the batch process into multiple transactions is not an option,
a second solution is to just write to indexes
after the call to `session.flush()`/`session.clear()`,
without waiting for the database transaction to be committed:
the internal document buffer will be cleared after each write to indexes.

This is done by calling the `execute()` method on the indexing plan,
as shown in the example below.

[IMPORTANT]
====
With this pattern, if an exception is thrown,
part of the data will already be in the index, with no way to roll back the changes,
while the database changes will have been rolled back.
The index will thus be inconsistent with the database.

To recover from that situation, you will have to either
execute the exact same database changes that failed manually
(to get the database back in sync with the index),
or <<indexing-plan,reindex the entities>> affected by the transaction manually
(to get the index back in sync with the database).

Of course, if you can afford to take the indexes offline for a longer period of time,
a simpler solution would be to wipe the indexes clean
and <<indexing-massindexer,reindex everything>>.
====

.A batch process with Hibernate Search using `execute()`
====
[source, JAVA, indent=0]
----
include::{sourcedir}/org/hibernate/search/documentation/mapper/orm/indexing/HibernateOrmManualIndexingIT.java[tags=persist-automatic-indexing-periodic-flush-execute-clear]
----
<1> Get the `SearchSession`.
<2> Get the search session's indexing plan.
<3> For every iteration of the loop, instantiate a new entity and persist it.
Note we're relying on automatic indexing to index the entity,
but this would work just as well if automatic indexing was disabled,
only requiring an extra call to index the entity.
See <<indexing-plan>>.
<4> After a `flush()`/`clear()`, call `indexingPlan.execute()`.
The entities will be processed and *the changes will be sent to the indexes immediately*.
Hibernate Search will wait for index changes to be "completed"
as required by the configured <<indexing-automatic-synchronization,synchronization strategy>>.
<5> After the loop, commit the transaction.
The remaining entities that were not flushed/cleared will be flushed and indexed automatically.
====
