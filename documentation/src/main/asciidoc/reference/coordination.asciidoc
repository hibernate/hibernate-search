[[coordination]]
= Coordination

[[coordination-basics]]
== Basics

include::components/coordination-comparison-note.asciidoc[]

An application using Hibernate Search usually relies on multiple threads,
or even multiple application instances,
which will update the database concurrently.

The coordination strategy defines how these threads/nodes will coordinate with each other
in order to update indexes according to these database updates,
in a way that ensures consistency,
prevents data loss,
and optimizes performance.

This strategy is set through configuration properties:

[source]
----
hibernate.search.coordination.strategy = outbox-polling
----

The default for this property is `none`.

[NOTE]
====
Coordination strategies are only available for the integration to Hibernate ORM.

See <<mapper-pojo-standalone-coordination,this section>> for information about
coordination in the Standalone POJO mapper.
====

See the following subsections for details about available strategies.

[[coordination-none]]
== No coordination

[[coordination-none-basics]]
=== Basics

The default strategy is the simplest and does not involve any additional infrastructure
for communication between application nodes.

All <<indexing-automatic,automatic indexing>> operations
are executed directly in application threads,
which gives this strategy the unique ability to provide <<indexing-plan-synchronization,synchronous indexing>>,
at the cost of a few limitations:

* <<limitations-parallel-embedded-update>>
* <<limitations-backend-indexing-error>>

include::components/coordination-comparison-note.asciidoc[]

[[coordination-none-indexing]]
=== How indexing works without coordination

[[coordination-none-indexing-detected-changes]]
Changes have to occur in the ORM session in order to be detected for <<indexing-automatic,automatic indexing>>::
See <<indexing-automatic-concepts-changes-in-session>> for more details.
[[coordination-none-indexing-association-consistency]]
Associations must be updated on both sides::
See <<limitations-changes-asymmetric-association-updates>> for more details.
[[coordination-none-indexing-change-filter]]
Only relevant changes trigger indexing::
See <<indexing-automatic-concepts-dirty-checking>> for more details.
[[coordination-none-indexing-on-flush]]
Entity data is extracted from entities upon session flushes or `SearchSession.close()`::
[[mapper-orm-indexing-automatic-concepts-extraction-on-flush]] When a Hibernate ORM session is flushed,
or (with the <<mapper-pojo-standalone,Standalone POJO Mapper>>) when `SearchSession.close()` is called,
Hibernate Search will extract data from the entities
to build documents to index,
and will put these documents in an internal buffer for
<<coordination-none-indexing-guarantee,later indexing>>.
This extraction <<coordination-none-indexing-lazy-loading,may involve loading extra data from the database>>.
+
[NOTE]
====
With the <<mapper-orm,Hibernate ORM integration>>,
the fact that this internal buffer is populated on Hibernate ORM session flush
means that you can safely `clear()` the session after a `flush()`:
entity changes performed up to the flush will be indexed correctly.

If you come from Hibernate Search 5 or earlier,
you may see this as a significant improvement:
there is no need to call `flushToIndexes()` and update indexes in the middle of a transaction anymore,
except for larger volumes of data (see <<mapper-orm-indexing-manual-indexingplan-process-execute>>).
====
+
However, if you perform a batch process inside a transaction with the <<mapper-orm,Hibernate ORM integration>>,
and call `session.flush()`/`session.clear()` regularly to save memory,
be aware that Hibernate Search's internal buffer holding documents to index
will grow on each flush, and will not be cleared until the transaction is committed or rolled back.
If you encounter memory issues because of that,
see <<mapper-orm-indexing-manual-indexingplan-process-execute>> for a few solutions.
[[coordination-none-indexing-lazy-loading]]
Extraction of entity data may fetch extra data from the database::
[[mapper-orm-indexing-automatic-concepts-indexing-triggers-lazy-loading]] Even when you change only a single property of an indexed entity,
if that property is indexed,
Hibernate Search needs to rebuild the corresponding document *in full*.
+
Hibernate Search tries to only load what is necessary for indexing,
but depending on your mapping, this may lead to lazy associations being loaded just to reindex entities,
even if you didn't need them in your business code,
which may represent an overhead for your application threads
as well as your database.
+
With the <<mapper-orm,Hibernate ORM integration>>, this extra cost can be mitigated to some extent by:
+
* leveraging Hibernate ORM's batch fetching:
see link:{hibernateDocUrl}#configurations-database-fetch[the `batch_fetch_size` property]
and link:{hibernateDocUrl}#fetching-batch[the `@BatchSize` annotation].
* leveraging Hibernate ORM's link:{hibernateDocUrl}#caching[second-level cache],
especially for immutable entities referenced from indexed entities
(e.g. for reference data such as countries, cities, ...).
[[coordination-none-indexing-guarantee]]
Indexing is not guaranteed on commit, but only after the application thread returns::
[[mapper-orm-indexing-automatic-concepts-transaction-commit]] When entity changes happen inside a transaction,
indexes are not updated immediately, but only after the transaction is successfully committed.
That way, if a transaction is rolled back, the indexes will be left in a state consistent with the database,
discarding all the index changes that were planned during the transaction.
+
Similarly, when using the <<mapper-pojo-standalone,Standalone POJO Mapper>>,
indexes are guaranteed to be updated after `SearchSession.close()` returns.
+
However, if an error occurs in the backend while indexing,
this behavior means that <<limitations-backend-indexing-error,index changes may be lost, leading to out-of-sync indexes>>.
If this is a problem for you, you should consider switching to <<coordination-outbox-polling,another coordination strategy>>.
+
[[mapper-orm-indexing-automatic-concepts-notransaction-flush]]
NOTE: With the <<mapper-orm,Hibernate ORM integration>>,
when entity changes happen outside any transaction (not recommended),
indexes are updated immediately upon session `flush()`.
Without that flush, indexes will not be updated automatically.
[[coordination-none-indexing-visibility]]
Index changes may not be visible immediately::
[[mapper-orm-indexing-automatic-concepts-nearrealtime]] By default, indexing will resume the application thread after index changes are committed to the indexes.
This means index changes are safely stored to disk,
but this does not mean a search query ran immediately after indexing will take the changes into account:
when using the Elasticsearch backend in particular, changes may take some time to be visible from search queries.
+
See <<indexing-plan-synchronization>> for details.

[[coordination-outbox-polling]]
== [[coordination-database-polling]] `outbox-polling`: additional event tables and polling in background processors

include::components/incubating-warning.asciidoc[]

[[coordination-outbox-polling-basics]]
=== [[coordination-database-polling-basics]] Basics

The `outbox-polling` strategy implements coordination through
<<coordination-outbox-polling-schema,additional tables>> in the application database.

<<indexing-automatic,Automatic indexing>> is implemented
by pushing events to an outbox table within the same transaction as the entity changes,
and polling this outbox table from background processors which perform indexing.

This strategy is able to provide guarantees that entities will be indexed regardless
of temporary I/O errors in backend,
at the cost of being only able to perform this indexing asynchronously.

The `outbox-polling` strategy can be enabled with the following settings:

[source]
----
hibernate.search.coordination.strategy = outbox-polling
----

[CAUTION]
====
If link:{hibernateDocUrl}#configurations-multi-tenancy[multi-tenancy] is enabled,
you will need extra configuration.

See <<coordination-outbox-polling-multi-tenancy>>.
====


You will also need to add this dependency:

[source, XML, subs="+attributes"]
----
<dependency>
   <groupId>org.hibernate.search</groupId>
   <artifactId>hibernate-search-mapper-orm-coordination-outbox-polling</artifactId>
   <version>{hibernateSearchVersion}</version>
</dependency>
----

include::components/coordination-comparison-note.asciidoc[]

[[coordination-outbox-polling-indexing]]
=== [[coordination-database-polling-indexing]] How indexing works with `outbox-polling` coordination

[[coordination-outbox-polling-indexing-detected-changes]]
Changes have to occur in the ORM session in order to be detected for <<indexing-automatic,automatic indexing>>::
See <<indexing-automatic-concepts-changes-in-session>> for more details.
[[coordination-outbox-polling-indexing-association-consistency]]
Associations must be updated on both sides::
See <<limitations-changes-asymmetric-association-updates>> for more details.
[[coordination-outbox-polling-indexing-change-filter]]
Only relevant changes trigger indexing::
See <<indexing-automatic-concepts-dirty-checking>> for more details.
[[coordination-outbox-polling-indexing-background]]
Indexing happens in a background thread::
When a Hibernate ORM session is flushed,
Hibernate Search will persist entity change events within the same Hibernate ORM session and the same transaction.
+
An <<coordination-outbox-polling-event-processor,event processor>> polls the database for new entity change events,
and asynchronously performs reindexing of the appropriate entities when it finds new events
(i.e. after the transaction is committed).
+
[NOTE]
====
The fact that events are persisted on session flush
means that you can safely `clear()` the session after a `flush()`:
entity changes events detected up to the flush will be persisted correctly.

If you come from Hibernate Search 5 or earlier,
you may see this as a significant improvement:
there is no need to call `flushToIndexes()` and update indexes in the middle of a transaction anymore.
====
[[coordination-outbox-polling-indexing-full-loading]]
The background processor will completely reload entities from the database::
The background processor responsible for reindexing entities
does not have access to the state of the link:{hibernateDocUrl}#best-practices-caching[first level cache]
when the entity change occurred, because it occurred in a different session.
+
This means each time an entity changes and has to be re-indexed,
the background process will load that entity in full.
Depending on your mapping, it may also need to load lazy associations to other entities.
+
This extra cost can be mitigated to some extent by:
+
* leveraging Hibernate ORM's batch fetching;
see link:{hibernateDocUrl}#configurations-database-fetch[the `batch_fetch_size` property]
and link:{hibernateDocUrl}#fetching-batch[the `@BatchSize` annotation].
* leveraging Hibernate ORM's link:{hibernateDocUrl}#caching[second-level cache],
especially for immutable entities referenced from indexed entities
(e.g. for reference data such as countries, cities, ...).
[[coordination-outbox-polling-indexing-guarantee]]
Indexing is guaranteed on transaction commit::
When entity changes happen inside a transaction,
Hibernate Search will persist entity change events within the same transaction.
+
If the transaction is committed, these events will be committed as well;
if it rolls back, the events will be rolled back as well.
This guarantees the events will eventually be processed by a background thread
and that the indexes will be updated accordingly,
but only when (if) the transaction succeeds.
+
[[coordination-outbox-polling-indexing-guarantee-notransaction]]
NOTE: When entity changes happen outside any transaction (not recommended),
events indexes are sent immediately after the session `flush()`.
Without that flush, indexes will not be updated automatically.
[[coordination-outbox-polling-indexing-visibility]]
Index changes will not be visible immediately::
By default, the application thread will resume after entity change events are committed to the database.
This means these changes are safely stored to disk,
but this does not mean a search query ran immediately when the thread resumes will take the changes into account:
<<coordination-outbox-polling-indexing-background,indexing will happen at a later time, asynchronously, in a background processor>>.
+
You can <<coordination-outbox-polling-event-processor,configure this event processor>> to run more often,
but it will remain asynchronous.

[[coordination-outbox-polling-schema]]
=== [[coordination-database-polling-schema]] Impact on the database schema
==== Basics
The `outbox-polling` coordination strategy needs to store data in additional tables in the application database,
so that this data can be consumed by background threads.

This includes in particular an outbox table, to which one row (representing a change event) is pushed every time an entity is changed
in a way that requires reindexing.

This also includes an agent table, where Hibernate Search registers every background event processor
in order to <<coordination-outbox-polling-sharding,dynamically assign shards>> to each application instance,
or simply to check that <<coordination-outbox-polling-sharding,statically assigned shards>>
are consistent.

These tables are accessed through entities that are automatically added to the Hibernate ORM configuration,
and as such they should be automatically generated when relying on Hibernate ORM's
link:{hibernateDocUrl}#configurations-hbmddl[automatic schema generation].

If you need to integrate the creation/dropping of these tables to your own script,
the easiest solution is to have Hibernate ORM generate DDL scripts for your whole schema
and copy everything related to constructs (tables, sequences, ...) prefixed with `HSEARCH_`.
See link:{hibernateDocUrl}#configurations-hbmddl[automatic schema generation],
in particular the Hibernate ORM properties `javax.persistence.schema-generation.scripts.action`,
`javax.persistence.schema-generation.scripts.create-target`
and `javax.persistence.schema-generation.scripts.drop-target`.

==== Custom schema/table name/etc.
By default, outbox and agent tables, mentioned in the previous section, are expected to be found
in the default catalog/schema, and are using uppercased table names prefixed with `HSEARCH_`.
Identity generator names used for these tables are prefixed with `HSEARCH_` and suffixed with `_GENERATOR`.

Sometimes there are specific naming conventions for database objects, or a need to separate the domain
and technical tables.
To allow some flexibility in this area, Hibernate Search provides a set of configuration properties
to specify catalog/schema/table names for outbox event and agent tables,
as well as an identity generator name for the agent table and a custom UUID generator strategy/data type for the outbox event table:

[source]
----
# Configure the agent mapping:
hibernate.search.coordination.entity.mapping.agent.catalog=CUSTOM_CATALOG
hibernate.search.coordination.entity.mapping.agent.schema=CUSTOM_SCHEMA
hibernate.search.coordination.entity.mapping.agent.generator=CUSTOM_AGENT_GENERATOR
hibernate.search.coordination.entity.mapping.agent.table=CUSTOM_AGENT_TABLE
# Configure the outbox event mapping:
hibernate.search.coordination.entity.mapping.outboxevent.catalog=CUSTOM_CATALOG
hibernate.search.coordination.entity.mapping.outboxevent.schema=CUSTOM_SCHEMA
hibernate.search.coordination.entity.mapping.outboxevent.table=CUSTOM_OUTBOX_TABLE
hibernate.search.coordination.entity.mapping.outboxevent.uuid_gen_strategy=time
hibernate.search.coordination.entity.mapping.outboxevent.preferred_uuid_jdbc_type=uuid-binary
----

* `agent.catalog` defines the database catalog to use for the agent table.
+
Defaults to the default catalog configured in Hibernate ORM.
* `agent.schema` defines the database schema to use for the agent table.
+
Defaults to the default schema configured in Hibernate ORM.
* `agent.table` defines the name of the agent table.
+
Defaults to `HSEARCH_AGENT`.
* `agent.generator` defines the name of the identifier generator used for the agent table .
+
Defaults to `HSEARCH_AGENT_GENERATOR`.

* `outboxevent.catalog` defines the database catalog to use for the outbox event table.
+
Defaults to the default catalog configured in Hibernate ORM.
* `outboxevent.schema` defines the database schema to use for the outbox event table.
+
Defaults to the default schema configured in Hibernate ORM.
* `outboxevent.table` defines the name of the outbox events table.
+
Defaults to `HSEARCH_OUTBOX_EVENT`.
* `outboxevent.uuid_gen_strategy` defines name of the UUID generator strategy used for the outbox event table. Available
options are `auto`/`random`/`time`. `auto` is a default and is the same as `random` which uses `UUID#randomUUID()`.
`time` is an IP based strategy consistent with IETF RFC 4122.
+
Defaults to `auto`.
* `outboxevent.preferred_uuid_jdbc_type` defines the database type used for representing an UUID
in the outbox event table. Available options are `default`/`uuid`/`uuid-binary`/`uuid-char`.
`default` is the default and will result into one of `uuid`/`uuid-binary`/`uuid-char` depending on the
database in use.
+
Defaults to `default`.

[TIP]
====
If your application relies on link:{hibernateDocUrl}#configurations-hbmddl[automatic database schema generation],
make sure that the underlying database supports catalogs/schemas
when specifying them. Also check if there are any constraints on name length and case sensitivity.
====

[TIP]
====
It is not required to provide all properties at the same time. For example, you can customize the schema only.
Unspecified properties will use their defaults.
====

[[coordination-outbox-polling-sharding]]
=== [[coordination-database-polling-sharding]] [[coordination-outbox-polling-sharding-static]] [[coordination-outbox-polling-sharding-basics]] Sharding and pulse

In order to avoid unnecessarily indexing the same entity multiple times on different application nodes,
Hibernate Search partitions the entities in what it calls "shards":

* Each entity belongs to exactly one shard.
* Each application node involved in <<coordination-outbox-polling-event-processor,event processing>>
is uniquely assigned one or more shards, and will only process events related to entities in these shards.

In order to reliably assign shards,
Hibernate Search <<coordination-outbox-polling-schema,adds an agent table to the database>>,
and uses that table to register agents involved in indexing (most of the time, one application instance = one agent =
the <<coordination-outbox-polling-event-processor,event processor>>).
The registered agents form a cluster.

To make sure that agents are always assigned one shard,
and that one shard is never assigned to more than one agent,
each agent will periodically perform a "pulse",
updating and inspecting the agent table.

What happens during a pulse depends on the type of agent.
During a "pulse":

* An <<coordination-outbox-polling-event-processor,event processor>> will:
** update its own entry in the agent table, to let other agents knows it's still active;
** forcibly remove entries from other agents if it detects that these agents expired
   (did not update their entry for a long time);
** detect and report configuration mistakes
   if using <<coordination-outbox-polling-sharding,static sharding>>,
   e.g. two agents assigned to the same shard;
** decide to suspend itself if a <<coordination-outbox-polling-mass-indexer,mass indexer>> is running;
** trigger rebalancing as necessary if using <<coordination-outbox-polling-event-processor-sharding,dynamic sharding>>;
   e.g. when it detects that new agents recently joined the cluster,
   or that agents left the cluster (voluntarily or forcibly).
* A <<coordination-outbox-polling-mass-indexer,mass indexer>> will:
** update its own entry in the agent table, to let other agents knows it's still active;
** forcibly remove entries from other agents if it detects that these agents expired
   (did not update their entry for a long time);
** switch to active waiting mode (frequent polling) if it notices some
   <<coordination-outbox-polling-event-processor,event processors>> are still running;
** switch to pulse-only mode (infrequent polling) and give the green light for mass indexing to start
  if it notices no <<coordination-outbox-polling-event-processor,event processors>> are running anymore.

For more details about dynamic and static sharding, see the following sections.

[[coordination-outbox-polling-event-processor]]
=== [[coordination-database-polling-processors]] Event processor

[[coordination-outbox-polling-event-processor-basics]]
==== Basics

Among agents of the `outbox-polling` coordination strategy executing in the background,
the most important one is the event processor:
it polls the outbox table for events
and then re-indexes the corresponding entities when new events are found.

The event processor can be configured using the following configuration properties:

[source]
----
hibernate.search.coordination.event_processor.enabled = true
hibernate.search.coordination.event_processor.polling_interval = 100
hibernate.search.coordination.event_processor.pulse_interval = 2000
hibernate.search.coordination.event_processor.pulse_expiration = 30000
hibernate.search.coordination.event_processor.batch_size = 50
hibernate.search.coordination.event_processor.transaction_timeout = 10
hibernate.search.coordination.event_processor.retry_delay = 15
----

* `event_processor.enabled` defines whether the event processor is enabled,
as a <<configuration-property-types,boolean value>>.
The default for this property is `true`, but it can be set to `false` to disable event processing on some application nodes,
for example to dedicate some nodes to HTTP request processing and other nodes to event processing.
* `event_processor.polling_interval` defines how long to wait for another query to the outbox events table
after a query didn't return any event,
as an <<configuration-property-types,integer value>> in milliseconds.
The default for this property is `100`.
+
High values mean higher latency between an entity change and the corresponding update in the index,
but less stress on the database when there are no events to process.
+
Low values mean lower latency between an entity change and the corresponding update in the index,
but more stress on the database when there are no events to process.
* `event_processor.pulse_interval` defines how long the event processor can poll for events
before it must perform a "pulse",
as an <<configuration-property-types,integer value>> in milliseconds.
The default for this property is `2000`.
+
See <<coordination-outbox-polling-sharding,the sharding basics>> for information about "pulses".
+
The pulse interval must be set to a value between the polling interval (see above) and one third (1/3) of the expiration interval (see below).
+
Low values (closer to the polling interval) mean less time wasted not processing events
when a node joins or leaves the cluster,
and reduced risk of wasting time not processing events
because an event processor is incorrectly considered disconnected,
but more stress on the database because of more frequent checks of the list of agents.
+
High values (closer to the expiration interval) mean more time wasted not processing events
when a node joins or leaves the cluster,
and increased risk of wasting time not processing events
because an event processor is incorrectly considered disconnected,
but less stress on the database because of less frequent checks of the list of agents.
* `event_processor.pulse_expiration` defines how long an event processor "pulse" remains valid
before considering the processor disconnected and forcibly removing it from the cluster,
as an <<configuration-property-types,integer value>> in milliseconds.
The default for this property is `30000`.
+
See <<coordination-outbox-polling-sharding,the sharding basics>> for information about "pulses".
+
The expiration interval must be set to a value at least 3 times larger than the pulse interval (see above).
+
Low values (closer to the pulse interval) mean less time wasted not processing events
when a node abruptly leaves the cluster due to a crash or network failure,
but increased risk of wasting time not processing events
because an event processor is incorrectly considered disconnected.
+
High values (much larger than the pulse interval) mean more time wasted not processing events
when a node abruptly leaves the cluster due to a crash or network failure,
but reduced risk of wasting time not processing events
because an event processor is incorrectly considered disconnected.
* `event_processor.batch_size` defines how many outbox events, at most, are processed in a single transaction
as an <<configuration-property-types,integer value>>.
The default for this property is `50`.
+
High values mean a lower number of transactions opened by the background process
and may increase performance thanks to the first-level cache (persistence context),
but will increase memory usage and in extreme cases may lead to `OutOfMemoryErrors`.
* `event_processor.transaction_timeout` defines the timeout for transactions processing outbox events
as an <<configuration-property-types,integer value>> in seconds.
+
Only effective when a JTA transaction manager is configured.
+
When using JTA and this property is not set, Hibernate Search will use whatever default transaction timeout is configured in the JTA transaction manager.
* `event_processor.retry_delay` defines how long the event processor must wait before re-processing an event after its processing failed,
as a <<configuration-property-types,positive integer value>> in seconds.
The default for this property is `30`.
+
Use the value `0` to reprocess failed events as soon as possible, with no delay.

[[coordination-outbox-polling-event-processor-sharding]]
==== [[coordination-database-polling-sharding-dynamic]] [[coordination-database-polling-sharding-static]] Sharding

By default, <<coordination-outbox-polling-sharding,sharding>> is dynamic:
Hibernate Search registers each application instance in the database,
and uses that information to dynamically assign a single, unique shard to each application instance,
updating assignments as instances start or stop.
Dynamic sharding does not accept any configuration beyond the
<<coordination-outbox-polling-event-processor-basics,basics>>.

If you want to configure sharding explicitly, you can use static sharding
by setting the following configuration properties:

[source]
----
hibernate.search.coordination.event_processor.shards.total_count = 4
hibernate.search.coordination.event_processor.shards.assigned = 0
----

* `shards.total_count` defines the total number of shards
as an <<configuration-property-types,integer value>>.
This property has no default and must be set explicitly if you want static sharding.
It must be set to the same value on all application nodes with assigned shards.
When this property is set, `shards.assigned` must also be set
* `shards.assigned` defines the shards assigned to the application node
as an <<configuration-property-types,integer value>>, or multiple comma-separated integer values.
This property has no default and must be set explicitly if you want static sharding.
When this property is set, `shards.total_count` must also be set.
+
Shards are referred to by an index in the range `[0, total_count - 1]` (see above for `total_count`).
A given application node must be assigned at least one shard
but may be assigned multiple shards by setting `shards.assigned` to a comma-separated list,
e.g. `0,3`.

[NOTE]
====
Each shard must be assigned to one and only one application node.

Event processing simply won't start until every shard has exactly one node.
====

.Example of static sharding settings
====
For example, the following configuration with 4 application nodes
would assign shard `0` to application node #0, shard `1` application node #1,
and no shard at all to application nodes #2 and #3:

[source]
----
# Node #0
hibernate.search.coordination.strategy = outbox-polling
hibernate.search.coordination.event_processor.shards.total_count = 2
hibernate.search.coordination.event_processor.shards.assigned = 0
----

[source]
----
# Node #1
hibernate.search.coordination.strategy = outbox-polling
hibernate.search.coordination.event_processor.shards.total_count = 2
hibernate.search.coordination.event_processor.shards.assigned = 1
----

[source]
----
# Node #2
hibernate.search.coordination.strategy = outbox-polling
hibernate.search.coordination.event_processor.enabled = false
----

[source]
----
# Node #3
hibernate.search.coordination.strategy = outbox-polling
hibernate.search.coordination.event_processor.enabled = false
----
====

[[coordination-outbox-polling-mass-indexer]]
=== Mass indexer

[[coordination-outbox-polling-mass-indexer-basics]]
==== Basics

During <<indexing-massindexer,mass indexing>>,
an application instance will exceptionally bypass <<coordination-outbox-polling-sharding,sharding>>
and index entities from any shard.

Bypassing sharding can be dangerous,
because indexing the same entity simultaneously from an event processor and the mass indexer
could potentially result in an out-of-sync index in some rare situations.
This is why, to be perfectly safe, event processing gets suspended while mass indexing is in progress.
Events are still produced and persisted, but their processing gets delayed until mass indexing finishes.

The suspension of event processing is achieved by registering a mass indexer agent in the agent table,
which event processors will eventually detect and react to by suspending themselves.
When mass indexing finishes, the mass indexer agent is removed from the agent table,
event processors detect that and resume event processing.

The mass indexer agent can be configured using the following configuration properties:

[source]
----
hibernate.search.coordination.mass_indexer.polling_interval = 100
hibernate.search.coordination.mass_indexer.pulse_interval = 2000
hibernate.search.coordination.mass_indexer.pulse_expiration = 30000
----

* `mass_indexer.polling_interval` defines how long to wait for another query to the agent table
when actively waiting for event processors to suspend themselves,
as an <<configuration-property-types,integer value>> in milliseconds.
The default for this property is `100`.
+
Low values will reduce the time it takes for the mass indexer agent to detect that event processors finally suspended themselves,
but will increase the stress on the database while the mass indexer agent is actively waiting.
+
High values will increase the time it takes for the mass indexer agent to detect that event processors finally suspended themselves,
but will reduce the stress on the database while the mass indexer agent is actively waiting.
* `mass_indexer.pulse_interval` defines how long the mass indexer can wait before it must perform a "pulse",
as an <<configuration-property-types,integer value>> in milliseconds.
The default for this property is `2000`.
+
See <<coordination-outbox-polling-sharding,the sharding basics>> for information about "pulses".
+
The pulse interval must be set to a value between the polling interval (see above) and one third (1/3) of the expiration interval (see below).
+
Low values (closer to the polling interval) mean reduced risk of
event processors starting to process events again during mass indexing
because a mass indexer agent is incorrectly considered disconnected,
but more stress on the database because of more frequent updates of the mass indexer agent's entry in the agent table.
+
High values (closer to the expiration interval) mean increased risk of
event processors starting to process events again during mass indexing
because a mass indexer agent is incorrectly considered disconnected,
but less stress on the database because of less frequent updates of the mass indexer agent's entry in the agent table.
* `mass_indexer.pulse_expiration` defines how long an event processor "pulse" remains valid
before considering the processor disconnected and forcibly removing it from the cluster,
as an <<configuration-property-types,integer value>> in milliseconds.
The default for this property is `30000`.
+
See <<coordination-outbox-polling-sharding,the sharding basics>> for information about "pulses".
+
The expiration interval must be set to a value at least 3 times larger than the pulse interval (see above).
+
Low values (closer to the pulse interval) mean less time wasted with event processors not processing events
when a mass indexer agent terminates due to a crash,
but increased risk of event processors starting to process events again during mass indexing
because a mass indexer agent is incorrectly considered disconnected.
+
High values (much larger than the pulse interval) mean more time wasted with event processors not processing events
when a mass indexer agent terminates due to a crash,
but reduced risk of event processors starting to process events again during mass indexing
because a mass indexer agent is incorrectly considered disconnected.

[[coordination-outbox-polling-multi-tenancy]]
=== Multi-tenancy

If you use link:{hibernateDocUrl}#configurations-multi-tenancy[Hibernate ORM's multi-tenancy support],
you will need to <<configuration-multi-tenancy,configure the list of all possible tenant identifiers>>.

Failing to mention a tenant identifier in this configuration might result in
events piling up in the outbox table without ever being <<coordination-outbox-polling-event-processor,processed>>,
or in exceptions being thrown upon <<coordination-outbox-polling-mass-indexer,mass indexing>>
due to incomplete configuration.

Apart from that, multi-tenancy support should be fairly transparent:
Hibernate Search will simply duplicate event processors for each tenant identifiers.

You can use different configuration for different tenants by using a different root for configuration properties:

* `hibernate.search.coordination` is the default root, whose properties will be used as a default for all tenants.
* `hibernate.search.coordination.tenants.<tenant ID>` is the tenant-specific root.

See below for an example.

.Configuration of coordination in a multi-tenant application with a node dedicated to a single tenant
====
Node 1:

[source]
----
hibernate.search.multi_tenancy.tenant_ids=tenant1,tenant2,tenant3,tenant4
hibernate.search.coordination.strategy = outbox-polling
hibernate.search.coordination.tenants.tenant1.event_processor.enabled = false <1>
----
<1> This node will process events for all tenants *except* `tenant1`.

Node 2:

[source]
----
hibernate.search.multi_tenancy.tenant_ids=tenant1,tenant2,tenant3,tenant4
hibernate.search.coordination.strategy = outbox-polling
hibernate.search.coordination.event_processor.enabled = false <1>
hibernate.search.coordination.tenants.tenant1.event_processor.enabled = true <2>
----
<1> This node will not process events for any tenant...
<2> ... *except* `tenant1`.
====

[[coordination-outbox-polling-aborted-events]]
=== [[_aborted_events]] Aborted events

If something goes wrong when an outbox event is processed, the event processor will try to re-process the events
two times, after that the event will be marked as aborted.
Aborted events won't be processed by the processor.

Hibernate Search exposes some APIs to work on aborted events.

.Use the API for the aborted events
====
[source, JAVA, indent=0, subs="+callouts"]
----
OutboxPollingSearchMapping searchMapping = Search.mapping( sessionFactory ).extension( OutboxPollingExtension.get() ); // <1>
long count = searchMapping.countAbortedEvents(); // <2>
searchMapping.reprocessAbortedEvents(); // <3>
searchMapping.clearAllAbortedEvents(); // <4>
----
<1> To have the access to the API we need to pass the `OutboxPollingExtension`
<2> Count aborted events
<3> Re-process aborted events
<4> Clear all the aborted events
====

If multi-tenancy is enabled, it will be necessary to pass
the tenant id to target the tenant operations are performed on.

.Use the API for the aborted events with multi-tenancy
====
[source, JAVA, indent=0, subs="+callouts"]
----
long count = searchMapping.countAbortedEvents( tenantId ); // <1>
searchMapping.reprocessAbortedEvents( tenantId ); // <2>
searchMapping.clearAllAbortedEvents( tenantId ); // <3>
----
<1> Count aborted events for the given tenantId
<2> Re-process aborted events for the given tenantId
<3> Clear all the aborted events for the given tenantId
====
