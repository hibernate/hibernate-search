[[getting-started]]
= Getting started

This section will guide you through the initial steps required
to integrate Hibernate Search into your application.

[NOTE]
====
Hibernate Search {hibernateSearchVersion} is currently a *technology preview*.

If you encounter problems, be sure to https://hibernate.atlassian.net/browse/HSEARCH[report them]:
new preview versions are released regularly.

Read http://hibernate.org/search/releases/6.0/#preview-status[the dedicated page on our website]
for more detailed and up-to-date information.
====

[[getting-started-compatibility]]
== Compatibility

.Compatibility

[cols="h,1", stripes=none]
|===============
|Java Runtime
|Java *8* or greater.
|Hibernate ORM (for the ORM mapper)
|Hibernate ORM *{hibernateVersion}*.
|JPA (for the ORM mapper)
|JPA *{jpaVersion}*.
|Apache Lucene (for the Lucene backend)
|Lucene *{luceneVersion}*.
|Elasticsearch server (for the Elasticsearch backend)
|Elasticsearch *{elasticsearchCompatibleVersions}*.
Other minor versions (e.g. {elasticsearchOtherPotentiallyCompatibleVersions}) may work
but are not given priority for bugfixes and new features.
|===============

[TIP]
====
Find more information for all versions of Hibernate Search on our
https://hibernate.org/search/releases/#compatibility-matrix[compatibility matrix].

The https://hibernate.org/community/compatibility-policy/[compatibility policy] may also be of interest.
====

[[getting-started-migrating]]
== Migration notes

If you are upgrading an existing application from an earlier version of Hibernate Search to the latest release,
make sure to check out the http://hibernate.org/search/documentation/migrate/[migration guide].

[WARNING]
====
**To Hibernate Search 5 users**

If you pull our artifacts from a Maven repository and you come from Hibernate Search 5,
be aware that just bumping the version number will not be enough.

In particular, the group IDs changed from `org.hibernate` to `org.hibernate.search`,
most of the artifact IDs changed to reflect the new mapper/backend design,
and the Lucene integration now requires an explicit dependency instead of being available by default.
Read <<gettingstarted-dependencies>> for more information.

Additionally, be aware that a lot of APIs changed, some only because of a package change,
others because of more fundamental changes
(like moving away from using Lucene types in Hibernate Search APIs).
====

[[gettingstarted-dependencies]]
== Dependencies

The Hibernate Search artifacts can be found in Maven's http://central.sonatype.org/[Central Repository].

If you do not want to, or cannot, fetch the JARs from a Maven repository,
you can get them from the
link:http://sourceforge.net/projects/hibernate/files/hibernate-search/{hibernateSearchVersion}/[distribution bundle hosted at Sourceforge].

In order to use Hibernate Search, you will need at least two direct dependencies:

* a dependency to the "mapper", which extracts data from your domain model and maps it to indexable documents;
* and a dependency to the "backend", which allows to index and search these documents.

Below are the most common setups and matching dependencies for a quick start;
read <<architecture>> for more information.

Hibernate ORM + Lucene::
Allows indexing of ORM entities in a single application node,
storing the index on the local filesystem.
+
If you get Hibernate Search from Maven, use these dependencies:
+
[source, XML, subs="+attributes"]
----
<dependency>
   <groupId>org.hibernate.search</groupId>
   <artifactId>hibernate-search-mapper-orm</artifactId>
   <version>{hibernateSearchVersion}</version>
</dependency>
<dependency>
   <groupId>org.hibernate.search</groupId>
   <artifactId>hibernate-search-backend-lucene</artifactId>
   <version>{hibernateSearchVersion}</version>
</dependency>
----
+
If you get Hibernate Search from the distribution bundle,
copy the JARs from `dist/engine`, `dist/mapper/orm`, `dist/backend/lucene`,
and their respective `lib` subdirectories.
Hibernate ORM + Elasticsearch::
Allows indexing of ORM entities on multiple application nodes,
storing the index on a remote Elasticsearch cluster (to be configured separately).
+
If you get Hibernate Search from Maven, use these dependencies:
+
[source, XML, subs="+attributes"]
----
<dependency>
   <groupId>org.hibernate.search</groupId>
   <artifactId>hibernate-search-mapper-orm</artifactId>
   <version>{hibernateSearchVersion}</version>
</dependency>
<dependency>
   <groupId>org.hibernate.search</groupId>
   <artifactId>hibernate-search-backend-elasticsearch</artifactId>
   <version>{hibernateSearchVersion}</version>
</dependency>
----
+
If you get Hibernate Search from the distribution bundle,
copy the JARs from `dist/engine`, `dist/mapper/orm`, `dist/backend/elasticsearch`,
and their respective `lib` subdirectories.

[[getting-started-configuration]]
== Configuration

Once you have added all required dependencies to your application,
it's time to have a look at the configuration file.

[TIP]
====
If you are new to Hibernate ORM, we recommend you start link:http://hibernate.org/quick-start.html[there]
to implement entity persistence in your application,
and only then come back here to add Hibernate Search indexing.
====

The configuration properties of Hibernate Search are sourced from Hibernate ORM,
so they can be added to any file from which Hibernate ORM takes its configuration:

* A `hibernate.properties` file in your classpath.
* The `hibernate.cfg.xml` file in your classpath, if using Hibernate ORM native bootstrapping.
* The `persistence.xml` file in your classpath, if using Hibernate ORM JPA bootstrapping.

Hibernate Search provides sensible defaults for all configuration properties,
but depending on your setup you might want to set the following:

.Hibernate Search properties in `persistence.xml` for a "Hibernate ORM + Lucene" setup
====
[source, XML, indent=0]
----
include::{resourcesdir}/META-INF/persistence.xml[tags=gettingstarted-configuration-orm_lucene]
----
<1> Set the location of indexes in the filesystem.
By default, the backend will store indexes in the current working directory.
====

.Hibernate Search properties in `persistence.xml` for a "Hibernate ORM + Elasticsearch" setup
====
[source, XML, indent=0]
----
include::{resourcesdir}/META-INF/persistence.xml[tags=gettingstarted-configuration-orm_elasticsearch]
----
<1> Set the Elasticsearch hosts to connect to.
By default, the backend will attempt to connect to `localhost:9200`.
<2> Set the protocol. The default is `http`, but you may need to use `https`.
<3> Set the username and password for basic HTTP authentication.
You may also be interested in <<backend-elasticsearch-configuration-aws,AWS IAM authentication>>.
====

[[getting-started-mapping]]
== Mapping

Let's assume that your application contains the Hibernate ORM managed classes `Book` and `Author`
and you want to index them in order to search the books contained in your database.

.Book and Author entities BEFORE adding Hibernate Search specific annotations
====
[source, JAVA, indent=0]
----
include::{sourcedir}/org/hibernate/search/documentation/gettingstarted/withouthsearch/Book.java[tags=include;!getters-setters]
----
[source, JAVA, indent=0]
----
include::{sourcedir}/org/hibernate/search/documentation/gettingstarted/withouthsearch/Author.java[tags=include;!getters-setters]
----
====

To make these entities searchable, you will need to map them to an index structure.
The mapping can be defined using annotations, or using a programmatic API;
this getting started guide will show you a simple annotation mapping.
For more details, refer to <<mapper-orm-mapping>>.

Below is an example of how the model above can be mapped.

.Book and Author entities AFTER adding Hibernate Search specific annotations
====
[source, JAVA, indent=0]
----
include::{sourcedir}/org/hibernate/search/documentation/gettingstarted/withhsearch/defaultanalysis/Book.java[tags=include;!getters-setters]
----
[source, JAVA, indent=0]
----
include::{sourcedir}/org/hibernate/search/documentation/gettingstarted/withhsearch/defaultanalysis/Author.java[tags=include;!getters-setters]
----
<1> `@Indexed` marks `Book` as indexed, i.e. an index will be created for that entity, and that index will be kept up to date.
<2> By default, the JPA `@Id` is used to generate a document identifier.
<3> `@FullTextField` maps a property to a full-text index field with the same name and type.
Full-text fields are broken down into tokens and normalized (lowercased, ...).
Here we're relying on default analysis configuration,
but most applications need to customize it;
this will be addressed further down.
<4> `@KeywordField` maps a property to a non-analyzed index field.
Useful for identifiers, for example.
<5> Hibernate Search is not just for full-text search: you can index non-`String` types with the `@GenericField` annotation,
A <<mapper-orm-directfieldmapping-supported-types,broad range of property types>> are supported out-of-the-box,
such as primitive types (`int`, `double`, ...) and their boxed counterpart (`Integer`, `Double`, ...),
enums, date/time types, `BigInteger`/`BigDecimal`, etc.
<6> `@IndexedEmbedded` "embeds" the indexed form of associated objects (entities or embeddables)
into the indexed form of the embedding entity.
+
Here, the `Author` class defines a single indexed field, `name`.
Thus adding `@IndexedEmbedded` to the `authors` property of `Book`
will add a single field named `authors.name` to the `Book` index.
This field will be populated automatically based on the content of the `authors` property,
and the books will be reindexed automatically whenever the `name` property of their author changes.
See <<mapper-orm-indexedembedded>> for more information.
<7> Entities that are only `@IndexedEmbedded` in other entities,
but do not require to be searchable by themselves, do not need to be annotated with `@Indexed`.
====

This is a very simple example, but is enough to get started.
Just remember that Hibernate Search allows more complex mappings:

* Multiple `@*Field` annotations exist, some of them allowing full-text search,
some of them allowing finer-grained configuration for field of a certain type.
You can find out more about `@*Field` annotations in <<mapper-orm-directfieldmapping>>.
* Properties, or even types, can be mapped with finer-grained control using "bridges".
This allows the mapping of types that are not supported out-of-the-box.
See <<mapper-orm-bridge>> for more information.

[[getting-started-initialization]]
== Initialization

Before the application is started for the first time,
some initialization may be required:

* The indexes and their schema need to be created.
* Data already present in the database (if any) needs to be indexed.

=== Schema management

Before indexing can take place, indexes and their schema need to be created,
either on disk (Lucene) or through REST API calls (Elasticsearch).

Fortunately, by default, Hibernate Search will take care of creating indexes on the first startup:
you don't have to do anything.

The next time the application is started, existing indexes will be re-used.

[NOTE]
====
Any change to your mapping (adding new fields, changing the type of existing fields, ...)
between two restarts of the application
will require an update to the index schema.

This will require some special handling, though it can easily be solved by dropping and re-creating the index.
See <<mapper-orm-mapping-changes>> for more information.
====

=== Initial indexing

As we'll see later, Hibernate Search takes care of triggering indexing
every time an entity changes in the application.

However, data already present in the database when you add the Hibernate Search integration
is unknown to Hibernate Search, and thus has to be indexed through a batch process.
To that end, you can use the mass indexer API, as shown in the following code:

.Using Hibernate Search MassIndexer API to manually (re)index the already persisted data
====
[source, JAVA, indent=0]
----
include::{sourcedir}/org/hibernate/search/documentation/gettingstarted/withhsearch/defaultanalysis/GettingStartedDefaultAnalysisIT.java[tags=manual-index]
----
<1> Get a Hibernate Search session, called `SearchSession`, from the `EntityManager`.
<2> Create an "indexer", passing the entity types you want to index.
To index all entity types, call `massIndexer()` without any argument.
<3> It is possible to set the number of threads to be used. For the complete list of options see <<mapper-orm-indexing-massindexer>>.
<4> Invoke the batch indexing process.
====

TIP: If no data is initially present in the database, mass indexing is not necessary.

[[getting-started-indexing]]
== Indexing

Hibernate Search will transparently index every entity persisted,
updated or removed through Hibernate ORM.
Thus this code would transparently populate your index:

.Using Hibernate ORM to persist data, and implicitly indexing it through Hibernate Search
====
[source, JAVA, indent=0]
----
include::{sourcedir}/org/hibernate/search/documentation/gettingstarted/withhsearch/defaultanalysis/GettingStartedDefaultAnalysisIT.java[tags=indexing]
----
====

[IMPORTANT]
====
By default, in particular when using the Elasticsearch backend,
changes will not be visible right after the transaction is committed.
A slight delay (by default one second) will be necessary for Elasticsearch to process the changes.

For that reason, if you modify entities in a transaction,
and then a execute search query right after that transaction,
the search results may not be consistent with the changes you just performed.

See <<mapper-orm-indexing-automatic-synchronization>> for more information about this behavior and how to tune it.
====

[[getting-started-searching]]
== Searching

Once the data is indexed, you can perform search queries.

The following code will prepare a search query targeting the index for the `Book` entity,
filtering the results so that at least one field among `title` and `authors.name`
contains the string `refactoring`.
The matches are implicitly on words ("tokens") instead of the full string,
and are case-insensitive: that's because the targeted fields are *full-text* fields.

.Using Hibernate Search to query the indexes
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/gettingstarted/withhsearch/defaultanalysis/GettingStartedDefaultAnalysisIT.java[tags=searching-lambdas]
----
<1> Get a Hibernate Search session, called `SearchSession`, from the `EntityManager`.
<2> Initiate a search query on the index mapped to the `Book` entity.
<3> Define that only documents matching the given predicate should be returned.
The predicate is created using a factory `f` passed as an argument to the lambda expression.
<4> Build the query and fetch the results, limiting to the top 20 hits.
<5> Retrieve the total number of matching entities.
<6> Retrieve matching entities.
<7> In case you're not interested in the whole result, but only in the hits,
you can also call `fetchHits()` directly.
====

If for some reason you don't want to use lambdas, you can use an alternative, object-based syntax,
but it will be a bit more verbose:

.Using Hibernate Search to query the indexes -- object-based syntax
====
[source, JAVA, indent=0]
----
include::{sourcedir}/org/hibernate/search/documentation/gettingstarted/withhsearch/defaultanalysis/GettingStartedDefaultAnalysisIT.java[tags=searching-objects]
----
<1> Get a Hibernate Search session, called `SearchSession`, from the `EntityManager`.
<2> Create a "search scope", representing the indexed types that will be queried.
<3> Initiate a search query targeting the search scope.
<4> Define that only documents matching the given predicate should be returned.
The predicate is created using the same search scope as the query.
<5> Build the query and fetch the results, limiting to the top 20 hits.
<6> Retrieve the total number of matching entities.
<7> Retrieve matching entities.
<8> In case you're not interested in the whole result, but only in the hits,
you can also call `fetchHits()` directly.
====

It is possible to get just the total hit count, using `fetchTotalHitCount()`.

.Using Hibernate Search to count the matches
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/gettingstarted/withhsearch/defaultanalysis/GettingStartedDefaultAnalysisIT.java[tags=counting]
----
<1> Fetch the total hit count.
====

Note that, while the examples above retrieved hits as managed entities,
it is just one of the possible hit types.
See <<search-dsl-projection>> for more information.

[[getting-started-analysis]]
== Analysis

Full-text search allows fast matches on words in a case-insensitive way,
which is one step further than substring search in a relational database.
But it can get much better: what if we want a search with the term "refactored"
to match our book whose title contains "refactoring"?
That's possible with custom analysis.

Analysis is how text is supposed to be processed when indexing and searching.
This involves _analyzers_,
which are made up of three types of components, applied one after the other:

* zero or (rarely) more character filters, to clean up the input text:
`A <strong>GREAT</strong> résume` => `A GREAT résume`.
* a tokenizer, to split the input text into words, called "tokens":
`A GREAT résume` => `[A, GREAT, résume]`.
* zero or more token filters, to normalize the tokens and remove meaningless tokens.
`[A, GREAT, résume]` => `[great, resume]`.

There are built-in analyzers,
in particular the default one, which will:

* tokenize (split) the input according to the Word Break rules
of the http://unicode.org/reports/tr29/[Unicode Text Segmentation algorithm];
* filter (normalize) tokens by turning uppercase letters to lowercase.

The default analyzer is a good fit for most language, but is not very advanced.
To get the most of analysis, you will need to define a custom analyzer
by picking the tokenizer and filters most suited to your specific needs.

The following paragraphs will explain how to configure and use
a simple yet reasonably useful analyzer.
For more information about analysis and how to configure it,
refer to the <<concepts-analysis>> section.

Each custom analyzer needs to be given a name in Hibernate Search.
This is done through analysis configurers, which are defined per backend:

. First, you need to implement an analysis configurer, a Java class that implements a backend-specific interface:
`LuceneAnalysisConfigurer` or `ElasticsearchAnalysisConfigurer`.
. Second, you need to alter the configuration of your backend to actually use your analysis configurer.

As an example, let's assume that one of your indexed `Book` entities has the title
"Refactoring: Improving the Design of Existing Code",
and you want to get hits for any of the following search terms:
"Refactor", "refactors", "refactored" and "refactoring".
One way to achieve this is to use an analyzer with the following components:

* A "standard" tokenizer, which splits words at whitespaces, punctuation characters and hyphens.
It is a good general-purpose tokenizer.
* A "lowercase" filter, which converts every character to lowercase.
* A "snowball" filter, which applies language-specific https://en.wikipedia.org/wiki/Stemming[stemming].

The examples below show how to define an analyzer with these components, depending on the backend you picked.

.Analysis configurer implementation and configuration in `persistence.xml` for a "Hibernate ORM + Lucene" setup
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/gettingstarted/withhsearch/customanalysis/MyLuceneAnalysisConfigurer.java[tags=include]
----
[source, XML, indent=0, subs="+callouts"]
----
include::{resourcesdir}/META-INF/persistence.xml[tags=gettingstarted-configuration-orm_lucene-analysis]
----
<1> Define a custom analyzer named "english", to analyze English text such as book titles.
<2> Set the tokenizer to a standard tokenizer. You need to pass factory classes to refer to components.
<3> Set the token filters. Token filters are applied in the order they are given.
<4> Set the value of a parameter for the last added char filter/tokenizer/token filter.
<5> Define another custom analyzer, named "name", to analyze author names.
On contrary to the first one, do not use enable stemming,
as it is unlikely to lead to useful results on proper nouns.
<6> Assign the configurer to the backend in the Hibernate Search configuration (here in `persistence.xml`).
====

.Analysis configurer implementation and configuration in `persistence.xml` for a "Hibernate ORM + Elasticsearch" setup
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/gettingstarted/withhsearch/customanalysis/MyElasticsearchAnalysisConfigurer.java[tags=include]
----
[source, XML, indent=0, subs="+callouts"]
----
include::{resourcesdir}/META-INF/persistence.xml[tags=gettingstarted-configuration-orm_elasticsearch-analysis]
----
<1> Define a custom analyzer named "english", to analyze English text such as book titles.
<2> Set the tokenizer to a standard tokenizer.
<3> Set the token filters. Token filters are applied in the order they are given.
<4> Note that, for Elasticsearch, any parameterized char filter, tokenizer or token filter
must be defined separately and assigned a name.
<5> Set the value of a parameter for the char filter/tokenizer/token filter being defined.
<6> Define another custom analyzer, named "name", to analyze author names.
On contrary to the first one, do not use enable stemming,
as it is unlikely to lead to useful results on proper nouns.
<7> Assign the configurer to the backend in the Hibernate Search configuration (here in `persistence.xml`).
====

Once analysis is configured, the mapping must be adapted to assign the relevant analyzer to each field:

.Book and Author entities after adding Hibernate Search specific annotations
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/gettingstarted/withhsearch/customanalysis/Book.java[tags=include;!getters-setters]
----
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/gettingstarted/withhsearch/customanalysis/Author.java[tags=include;!getters-setters]
----
<1> Replace the `@GenericField` annotation with `@FullTextField`,
and set the `analyzer` parameter to the name of the custom analyzer configured earlier.
====

That's it! Now, once the entities will be reindexed, you will be able to search for the terms
"Refactor", "refactors", "refactored" or "refactoring",
and the book entitled "Refactoring: Improving the Design of Existing Code"
will show up in the results.

[IMPORTANT]
====
Mapping changes are not auto-magically applied to already-indexed data.
Unless you know what you are doing, you should remember to reindex your data
after you changed the Hibernate Search mapping of your entities.
====

.Using Hibernate Search to query the indexes after analysis was configured
====
[source, JAVA, indent=0]
----
include::{sourcedir}/org/hibernate/search/documentation/gettingstarted/withhsearch/customanalysis/GettingStartedCustomAnalysisIT.java[tags=searching]
----
====

== What's next

The above paragraphs gave you an overview of Hibernate Search.
The next step after this tutorial is to get more familiar
with the overall architecture of Hibernate Search (<<architecture>>)
and explore the basic features in more detail.

Two topics which were only briefly touched in this tutorial
were analysis configuration (<<concepts-analysis>>) and bridges (<<mapper-orm-bridge>>).
Both are important features required for more fine-grained indexing.

When it comes to initializing your index, you will be interested
in <<mapper-orm-schema-management,schema management>>
and <<mapper-orm-indexing-massindexer,mass indexing>>.

When querying, you will probably want to know more about
<<search-dsl-predicate,predicates>>,
<<search-dsl-sort,sorts>>, <<search-dsl-projection,projections>>,
<<search-dsl-aggregation,aggregations>>.

You can also have a look at sample applications:

* The link:https://github.com/quarkusio/quarkus-quickstarts/tree/master/hibernate-search-elasticsearch-quickstart[Quarkus quickstart],
a sample application using Hibernate Search with the [Quarkus](https://quarkus.io/) framework.
* The link:https://github.com/hibernate/hibernate-search/tree/master/integrationtest/showcase/library["Library" showcase],
a sample application using Hibernate Search with the [Spring Boot](https://spring.io/projects/spring-boot) framework.
