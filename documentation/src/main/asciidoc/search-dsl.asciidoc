[[search-dsl]]
= Searching
// Search 5 anchors backward compatibility
[[search-query-querydsl]]

Beyond simply indexing, Hibernate Search also exposes high-level APIs to search these indexes
without having to resort to native APIs.

One key feature of these search APIs is the ability to use indexes to perform the search,
but to return entities loaded *from the database*,
effectively offering a new type of query for Hibernate ORM entities.

[[search-dsl-query]]
== Query DSL
// Search 5 anchors backward compatibility
[[search-query]]

[[search-dsl-query-generality]]
=== Basics
// Search 5 anchors backward compatibility
[[_building_a_hibernate_search_query]]

Preparing and executing a query requires just a few lines:

.Executing a search query
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/search/query/QueryDslIT.java[tags=entryPoint]
----
<1> Get a Hibernate Search session, called `SearchSession`, from the `EntityManager`.
<2> Initiate a search query on the index mapped to the `Book` entity.
<3> Define that only documents matching the given predicate should be returned.
The predicate is created using a factory `f` passed as an argument to the lambda expression.
See <<search-dsl-predicate>> for more information about predicates.
<4> Build the query and fetch the results, limiting to the top 20 hits.
<5> Retrieve the total number of matching entities.
<6> Retrieve matching entities.
====

By default, the hits of a search query will be entities managed by Hibernate ORM,
bound to the entity manager used to create the search session.
This provides all the benefits of Hibernate ORM,
in particular the ability to navigate the entity graph to retrieve associated entities if necessary.

The query DSL offers many features, detailed in the following sections.
Some commonly used features include:

* <<search-dsl-predicate,predicates>>,
the main component of a search query,
i.e. the condition that every document must satisfy in order to be included in search results.
* <<search-dsl-query-fetching-results,fetching the results differently>>:
getting the hits directly as a list,
using pagination, scrolling, etc.
* <<search-dsl-sort,sorts>>,
to order the hits in various ways:
by score, by the value of a field, by distance to a point, etc.
* <<search-dsl-projection,projections>>,
to retrieve hits that are not just managed entities:
data can be extracted from the index (field values),
or even from both the index and the database.
* <<search-dsl-aggregation,aggregations>>,
to group hits and compute aggregated metrics for each group -- hit count by category, for example.

[[search-dsl-query-targeting]]
=== Advanced entity types targeting

[[search-dsl-query-targeting-multiple]]
==== Targeting multiple entity types

When multiple entity types have similar indexed fields,
it is possible to search across these multiple types in a single search query:
the search result will contain hits from any of the targeted types.

.Targeting multiple entity types in a single search query
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/search/query/QueryDslIT.java[tags=targeting-multiple]
----
<1> Initiate a search query targeting the indexes mapped to the `Manager` and `Associate` entity types.
Since both entity types implement the `Person` interface,
search hits will be instances of `Person`.
<2> Continue building the query as usual.
There are restrictions regarding the fields that can be used: see the note below.
<3> Fetch the search result. Hits will all be instances of `Person`.
====

[NOTE]
====
Multi-entity (multi-index) searches will only work well as long
as the fields referenced in predicates/sorts/etc. are identical in all targeted indexes (same type, same analyzer, ...).
Fields that are defined in only one of the targeted indexes will also work correctly.

If you want to reference index fields that are even *slightly* different
in one of the targeted indexes (different type, different analyzer, ...),
see <<search-dsl-multiple-fields>>.
====

[[search-dsl-query-targeting-entityName]]
==== Targeting entity types by name

Though rarely necessary, it is also possible to use entity names instead of classes
to designate the entity types targeted by the search:

.Targeting entity types by name
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/search/query/QueryDslIT.java[tags=targeting-entityName]
----
<1> Initiate a search query.
<2> Pass a custom scope encompassing the indexes mapped to the `Manager` and `Associate` entity types,
expecting those entity types to implement the `Person` interface (Hibernate Search will check that).
<3> Continue building the query as usual.
<4> Fetch the search result. Hits will all be instances of `Person`.
====

[[search-dsl-query-fetching-results]]
=== Fetching results
// Search 5 anchors backward compatibility
[[_retrieving_the_results]]

[[search-dsl-query-fetching-results-basics]]
==== Basics
// Search 5 anchors backward compatibility
[[_result_size]]

In Hibernate Search, the default search result is a little bit more complicated than just "a list of hits".
This is why the default methods return a composite `SearchResult` object offering getters
to retrieve the part of the result you want,
as shown in the example below.

.Getting information from a `SearchResult`
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/search/query/QueryDslIT.java[tags=fetching-searchResult]
----
<1> Start building the query as usual.
<2> Fetch the results, limiting to the top 20 hits.
<3> Retrieve the total hit count, i.e. the total number of matching entities/documents,
which could be 10,000 even if you only retrieved the top 20 hits.
This is useful to give end users and idea of how many more hits they query produced.
<4> Retrieve the top hits, in this case the top 20 matching entities/documents.
<5> Other kinds of results and information can be retrieved from `SearchResult`.
They are explained in dedicated sections, such as <<search-dsl-aggregation>>.
====

It is possible to retrieve the total hit count alone,
for cases where only the number of hits is of interest,
not the hits themselves:

.Getting the total hit count directly
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/search/query/QueryDslIT.java[tags=fetching-totalHitCount]
----
====

The top hits can also be obtained directly,
without going through a `SearchResult`,
which can be handy if only the top hits are useful, and not the total hit count:

.Getting the top hits directly
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/search/query/QueryDslIT.java[tags=fetching-hits]
----
====

If only zero to one hit is expected, it is possible to retrieve it as an `Optional`.
An exception will be thrown if more than one hits are returned.

.Getting the only hit directly
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/search/query/QueryDslIT.java[tags=fetching-singleHit]
----
====

[[search-dsl-query-fetching-results-all]]
==== Fetching all hits

[WARNING]
====
Fetching all hits is rarely a good idea:
if the query matches many entities/documents,
this may lead to loading millions of entities in memory,
which will likely crash the JVM,
or at the very least slow it down to a crawl.

If you know your query will always have less than N hits,
consider setting the limit to N to avoid memory issues.

If there is no bound to the number of hits you expect,
you should consider <<search-dsl-query-fetching-results-pagination>>
or <<search-dsl-query-fetching-results-scrolling>>
to retrieve data in batches.

If you still want to fetch all hits in one call,
be aware that the Elasticsearch backend will only ever return 10,000 hits at a time,
due to internal safety mechanisms in the Elasticsearch cluster.
====

.Getting all hits in a `SearchResult`
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/search/query/QueryDslIT.java[tags=fetching-all-searchResult]
----
====

.Getting all hits directly
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/search/query/QueryDslIT.java[tags=fetching-all-hits]
----
====

[[search-dsl-query-fetching-results-pagination]]
==== Pagination
// Search 5 anchors backward compatibility
[[_pagination]]

Pagination is the concept of splitting hits in successive "pages",
all pages containing a fixed number of elements (except potentially the last one).
When displaying results on a web page,
the user will be able to go to an arbitrary page and see the corresponding results,
for example "results 151 to 170 of 14,265".

Pagination is achieved in Hibernate Search by passing an offset and a limit to the `fetch` or `fetchHits` method:

* The offset defines the number of documents that should be skipped because they were displayed in previous pages.
It is a *number of documents*, not a number of pages,
so you will usually want to compute it from the page number and page size this way:
`offset = zero-based-page-number * page-size`.
* The limit defines the maximum number of hits to return, i.e. the page size.

.Pagination retrieving a `SearchResult`
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/search/query/QueryDslIT.java[tags=fetching-pagination-searchResult]
----
<1> Set the offset to `40` and the limit to `20`.
====

.Pagination retrieving hits directly
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/search/query/QueryDslIT.java[tags=fetching-pagination-hits]
----
<1> Set the offset to `40` and the limit to `20`.
====

[[search-dsl-query-fetching-results-scrolling]]
==== Scrolling
// Search 5 anchors backward compatibility
[[_performance_considerations]]

include::todo-placeholder.asciidoc[]

// TODO https://docs.jboss.org/hibernate/search/5.11/reference/en-US/html_single/#_performance_considerations

[[search-dsl-query-routing]]
=== Routing

include::components/sharding-intro-note.asciidoc[]

This feature is useful when sharding is enabled,
and when each entity is mapped in such a way that
<<mapper-orm-bridge-routingkeybridge,it is assigned a routing key>>.

If a search query already uses predicates to filter documents in such a way that
all matching documents will have a routing key in a known subset of all possible routing keys,
it is possible to specify these routing keys to Hibernate Search
so that only the relevant shards are queried,
potentially improving performance.

[WARNING]
====
The main purpose of this feature is to *improve performance*.
It should not be relied on for document filtering purposes.

While setting a routing key will remove some irrelevant documents from the hits,
it may not remove _all_ of them: the routing key will resolve into a single shard,
but that shard may be contain documents with multiple different routing keys,
depending on the sharding strategy.

Thus, even when specifying a routing key that supposedly has the same value
as a field in the document (e.g. a `genre` field),
it is necessary to also add a predicate to explicitly filter out documents
that may not have the same routing key.
====

Specifying routing keys is done by calling the `.routing(String)` or .`routing(Collection<String>)` methods
when building the query:

.Routing a query to a subset of all shards
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/mapper/orm/routing/HibernateOrmRoutingIT.java[tags=routing-single]
----
<1> Start building the query.
<2> Define that only documents matching the given `genre` should be returned.
<3> In this case, the entity is mapped in such a way that the `genre` is also used as a routing key.
We know all documents will have the given `genre` value,
so we can specify the routing key to limit the query to relevant shards.
<4> Build the query and fetch the results.
====

[[search-dsl-query-entity-loading-options]]
=== Entity loading options

Hibernate Search executes database queries to load entities
that are returned as part of the hits of a search query.

This section presents all available options related to entity loading in search queries.

[[search-dsl-query-cache-lookup-strategy]]
==== Cache lookup strategy
// Search 5 anchors backward compatibility
[[_customizing_object_initialization_strategies]]

By default, Hibernate Search will load entities from the database directly,
without looking at any cache.
This is a good strategy when the size of caches (Hibernate ORM session or second level cache)
is much lower than the total number of indexed entities.

If a significant portion of your entities are present in the second level cache,
you can force Hibernate Search to retrieve entities from the persistence context (the session)
and/or the second level cache if possible.
Hibernate Search will still need to execute a database query to retrieve entities missing from the cache,
but the query will likely have to fetch fewer entities,
leading to better performance and lower stress on your database.

This is done through the cache lookup strategy,
which can be configured by setting the configuration property `hibernate.search.query.loading.cache_lookup.strategy`:

* `skip` (the default) will not perform any cache lookup.
* `persistence-context` will only look into the persistence context,
i.e. will check if the entities are already loaded in the session.
Useful if most search hits are expected to already be loaded in session,
which is generally unlikely.
* `persistence-context-then-second-level-cache` will first look into the persistence context,
then into the second level cache, if enabled in Hibernate ORM for the searched entity.
Useful if most search hits are expected to be cached,
which may be likely if you have a small number of entities and a large cache.

[NOTE]
====
Before a second-level cache can be used for a given entity type,
some configuration is required in Hibernate ORM.

See link:{hibernateDocUrl}#caching[the caching section of the Hibernate ORM documentation]
for more information.
====

It is also possible to override the configured strategy on a per-query basis, as shown below.

.Overriding the cache lookup strategy in a single search query
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/search/query/QueryDslIT.java[tags=cacheLookupStrategy-persistenceContextThenSecondLevelCache]
----
<1> Start building the query.
<2> Mention that the persistence context and second level cache should be checked
before entities are loaded from the database.
<3> Fetch the results.
The more entities found in the persistence context or second level cache,
the less entities will be loaded from the database.
====

[[search-dsl-query-fetch-size]]
==== Fetch size

By default, Hibernate Search will use a fetch size of `100`,
meaning that for a single `fetch*()` call on a single query,
it will run a first query to load the first 100 entities,
then if there are more hits it will run a second query to load the next 100,
etc.

The fetch size can be configured by setting the configuration property `hibernate.search.query.loading.fetch_size`.
This property expects a strictly positive <<configuration-property-types,Integer value>>.

It is also possible to override the configured fetch size on a per-query basis, as shown below.

.Overriding the fetch size in a single search query
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/search/query/QueryDslIT.java[tags=fetchSize]
----
<1> Start building the query.
<2> Set the fetch size to an arbitrary value (must be `1` or more).
<3> Fetch the results, limiting to the top 200 hits.
One query will be executed to load the hits if there are less hits than the given fetch size;
two queries if there are more hits than the fetch size but less than twice the fetch size,
etc.
====

==== Entity graph
// Search 5 anchors backward compatibility
[[_fetching_strategy]]

include::todo-placeholder.asciidoc[]

// TODO HSEARCH-3628 https://docs.jboss.org/hibernate/search/5.11/reference/en-US/html_single/#_fetching_strategy

[[search-dsl-query-timeout]]
=== Timeout
// Search 5 anchors backward compatibility
[[_limiting_the_time_of_a_query]]

You can limit the time it takes for a search query to execute in two ways:

* Aborting (throwing an exception) when the time limit is reached with `failAfter()`.
* Truncating the results when the time limit is reached with `truncateAfter()`.

[WARNING]
====
Currently, the two approaches are incompatible:
trying to set both `failAfter` and `truncateAfter` will result in unspecified behavior.
====

==== `failAfter()`: Aborting the query after a given amount of time
// Search 5 anchors backward compatibility
[[_raise_an_exception_on_time_limit]]

By calling `failAfter(...)` when building the query,
it is possible to set a time limit for the query execution.
Once the time limit is reached,
Hibernate Search will stop the query execution and throw a `SearchTimeoutException`.

include::components/timeout-besteffort-note.asciidoc[]

.Triggering a failure on timeout
====
[source, JAVA]
----
include::{sourcedir}/org/hibernate/search/documentation/search/query/QueryDslIT.java[tags=failAfter]
----
<1> Build the query as usual.
<2> Call `failAfter` to set the timeout.
<3> Fetch the results.
<4> Catch the exception if necessary.
====

[NOTE]
====
`explain()` does not honor this timeout:
this method is used for debugging purposes and in particular to find out why a query is slow.
====

==== `truncateAfter()`: Truncating the results after a given amount of time
// Search 5 anchors backward compatibility
[[_limit_the_number_of_results_when_the_time_limit_is_reached]]

By calling `truncateAfter(...)` when building the query,
it is possible to set a time limit for the collection of search results.
Once the time limit is reached,
Hibernate Search will stop collecting hits and return an incomplete result.

include::components/timeout-besteffort-note.asciidoc[]

.Truncating the results on timeout
====
[source, JAVA]
----
include::{sourcedir}/org/hibernate/search/documentation/search/query/QueryDslIT.java[tags=truncateAfter]
----
<1> Build the query as usual.
<2> Call `truncateAfter` to set the timeout.
<3> Fetch the results.
<4> Optionally extract _took_: how much time the query took to execute.
<5> Optionally extract _timedOut_: whether the query timed out.
====

[NOTE]
====
`explain()` and `fetchTotalHitCount()` do not honor this timeout.
The former is used for debugging purposes and in particular to find out why a query is slow.
For the latter it does not make sense to return a _partial_ result.
====

[[search-dsl-query-object]]
=== Obtaining a query object

The example presented in most of this documentation fetch the query results
directly at the end of the query definition DSL,
not showing any "query" object that can be manipulated.
This is because the query object generally only makes code more verbose
without bringing anything worthwhile.

However, in some cases a query object can be useful.
To get a query object, just call `toQuery()` at the end of the query definition:

.Getting a `SearchQuery` object
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/search/query/QueryDslIT.java[tags=searchQuery]
----
<1> Build the query as usual.
<2> Retrieve a `SearchQuery` object.
<3> Fetch the results.
====

This query object supports all <<search-dsl-query-fetching-results,`fetch*` methods supported by the query DSL>>.
The main advantage over calling these methods directly at the end of a query definition
is mostly related to debugging (see <<search-dsl-query-debugging>>),
but the query object can also be useful if you need an adapter to another API.

Hibernate Search provides an adapter to JPA and Hibernate ORM's native APIs,
i.e. a way to turn a `SearchQuery` into a `javax.persistence.TypedQuery` (JPA)
or a `org.hibernate.query.Query` (native ORM API):

.Getting a `SearchQuery` object
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/search/query/QueryDslIT.java[tags=searchQuery-toORM]
----
<1> Build the query as usual.
<2> Retrieve a `SearchQuery` object.
<3> Turn the `SearchQuery` object into a JPA query.
<4> Turn the `SearchQuery` object into a Hibernate ORM query.
====

// Search 5 anchors backward compatibility
[[_resulttransformer]]
[WARNING]
====
The resulting query *does not support all operations*,
so is recommended to only convert search queries when absolutely required,
for example when integrating with code that only works with Hibernate ORM queries.

The following operations are expected to work correctly in most cases,
even though they may behave slightly differently from what is expected from a JPA `TypedQuery`
or Hibernate ORM `Query` in some cases
(including, but not limited to, the type of thrown exceptions):

* Hit retrieval methods (`list`, `getResultList`, `uniqueResult`, ... ).
* `setFirstResult`/`setMaxResults` and getters.
* `setFetchSize`
* `unwrap`

The following operations are known not to work correctly,
with no plan to fix them at the moment:

* Hints (`setHint`, ...).
* Parameter-related methods (`setParameter`, ...).
* Result transformer (`setResultTransformer`, ...);
use <<search-dsl-projection-composite,composite projections>> instead.
* Lock-related methods (`setLockOptions`, ...).
* And more (this list is not exhaustive).
====

[[search-dsl-query-debugging]]
=== Debugging a query

[[search-dsl-query-debugging-matches]]
==== Explaining matches

When some documents unexpectedly match or don't match,
you will need information about the exact query being executed,
and about the index content.

To gain insight about what ends up being executed exactly,
one option is to <<search-dsl-query-object,create a `SearchQuery` object>>
using `toQuery()` at the end of the query definition,
then call `toString()` to get a String representation of that query.

Another option is to take advantage of logs:
all executed search queries are logged to the log category `org.hibernate.search.query`
at the `DEBUG` level.

You may also need to inspect the content of the index.
This is rather obvious with Elasticsearch: run simpler queries using either Hibernate Search or the REST APIs directly.
For the Lucene backend,
https://medium.com/@mocobeta/luke-become-an-apache-lucene-module-as-of-lucene-8-1-7d139c998b2[use the Luke tool]
distributed as part of the https://lucene.apache.org/core/downloads.html[Lucene binary packages].

[[search-dsl-query-debugging-scores]]
==== Explaining scores
// Search 5 anchors backward compatibility
[[_understanding_results]]

When the score of some documents is higher or lower than expected,
the best way to gain insight is to <<search-dsl-query-object,create a `SearchQuery` object>>
using `toQuery()` at the end of the query definition,
and then use the backend-specific `explain` methods;
the result of these methods will explain how the score of a specific document was computed.
See below for examples.

To retrieve an explanation for all matches in one call,
`explanation` projections are available:
see <<search-dsl-projection-extensions-lucene-explanation,here for Lucene>>
and <<search-dsl-projection-extensions-elasticsearch-explanation,here for Elasticsearch>>.

[WARNING]
====
Regardless of the API used, explanations are rather costly performance-wise:
only use them for debugging purposes.
====

.Retrieving score explanation -- Lucene
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/search/query/QueryDslIT.java[tags=explain-lucene]
----
<1> Build the query as usual,
but using the Lucene extension so that the retrieved query exposes Lucene-specific operations.
<2> Retrieve a `SearchQuery` object.
<3> Retrieve the explanation of the score of the document with ID `1`.
The explanation is of type `Explanation`, but you can convert it to a readable string using `toString()`.
<4> For multi-index queries, it is necessary to refer to the document not only by its ID,
but also by the name of the index it's located in.
<5> If you cannot change the code building the query to use the Lucene extension,
you can instead use the Lucene extension on the `SearchQuery` to convert it after its creation.
====

.Retrieving score explanation -- Elasticsearch
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/search/query/QueryDslIT.java[tags=explain-elasticsearch]
----
<1> Build the query as usual,
but using the Elasticsearch extension so that the retrieved query exposes Elasticsearch-specific operations.
<2> Retrieve a `SearchQuery` object.
<3> Retrieve the explanation of the score of the document with ID `1`.
<4> For multi-index queries, it is necessary to refer to the document not only by its ID,
but also by the name of the index it's located in.
<5> If you cannot change the code building the query to use the Elasticsearch extension,
you can instead use the Elasticsearch extension on the `SearchQuery` to convert it after its creation.
====

==== Query metadata in SearchResult: `took` and `timed_out`

.Returning query execution time and whether a timeout occurred
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/search/query/QueryDslIT.java[tags=took-timedOut]
----
<1> Fetch the results.
<2> Extract _took_: how much time the query took
(in case of Elasticsearch, ignoring network latency between the application and the Elasticsearch cluster).
<3> Extract _timedOut_: whether the query timed out
(in case of Elasticsearch, ignoring network latency between the application and the Elasticsearch cluster).
====

[[search-dsl-query-elasticsearch-json]]
=== Elasticsearch: leveraging advanced features with JSON manipulation

include::components/experimental-warning.asciidoc[]

Elasticsearch ships with many features.
It is possible that at some point, one feature you need will not be exposed by the Search DSL.

To work around such limitations, Hibernate Search provides ways to:

* Transform the HTTP request sent to Elasticsearch for search queries.
* Read the raw JSON of the HTTP response received from Elasticsearch for search queries.

include::components/elasticsearch-request-response-warning.asciidoc[]

Most simple use cases will only need to change the HTTP request slightly, as shown below.

.Transforming the Elasticsearch request manually in a search query
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/search/query/QueryDslIT.java[tags=elasticsearch-requestTransformer]
----
<1> Build the query as usual,
but using the Elasticsearch extension so that Elasticsearch-specific options are available.
<2> Add a request transformer to the query.
Its `transform` method will be called whenever a request is about to be sent to Elasticsearch.
<3> Inside the `transform` method, alter the HTTP query parameters.
<4> It is also possible to alter the request's JSON body as shown here,
or even the request's path (not shown in this example).
<5> Retrieve the result as usual.
====

For more complicated use cases, it is possible to access the raw JSON of the HTTP response, as shown below.

.Accessing the Elasticsearch response body manually in a search query
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/search/query/QueryDslIT.java[tags=elasticsearch-responseBody]
----
<1> Build the query as usual,
but using the Elasticsearch extension so that Elasticsearch-specific options are available.
<2> Add a request transformer to the query.
<3> Add content to the request body,
so that Elasticsearch will return more data in the response.
Here we're asking Elasticsearch to apply a link:{elasticsearchDocUrl}/search-suggesters.html[suggester].
<4> Retrieve the result as usual.
Since we used the Elasticsearch extension when building the query,
the result will have an Elasticsearch-specific type: `ElasticsearchSearchResult`.
<5> Get the response body as a `JsonObject`.
<6> Extract useful information from the response body.
Here we're extracting the result of the suggester we configured above.
or even the request's path (not shown in this example).
====

[NOTE]
====
Gson's API for building JSON objects is quite verbose,
so the example above relies on a small, custom helper method to make the code more readable:

[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/search/query/QueryDslIT.java[tags=elasticsearch-responseBody-helper]
----
====

[TIP]
====
When data needs to be extracted from each hit,
it is often more convenient to use the <<search-dsl-projection-extensions-elasticsearch-jsonHit,`jsonHit` projection>>
than parsing the whole response.
====

[[search-dsl-predicate]]
== Predicate DSL
// Search 5 anchors backward compatibility
[[query-predicate]]

// TODO add more than just examples in the sub-sections

[[search-dsl-predicate-concepts]]
=== Basics

The main component of a search query is the _predicate_,
i.e. the condition that every document must satisfy in order to be included in search results.

The predicate is configured when building the search query:

.Defining the predicate of a search query
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/search/predicate/PredicateDslIT.java[tags=entryPoint-lambdas]
----
<1> Start building the query.
<2> Mention that the results of the query are expected to have a `title` field matching the value `robot`.
If the field does not exist or cannot be searched on, an exception will be thrown.
<3> Fetch the results, which will match the given predicate.
====

Or alternatively, if you don't want to use lambdas:

.Defining the predicate of a search query -- object-based syntax
====
[source, JAVA, indent=0]
----
include::{sourcedir}/org/hibernate/search/documentation/search/predicate/PredicateDslIT.java[tags=entryPoint-objects]
----
====

The predicate DSL offers more predicate types, and multiple options for each type of predicate.
To learn more about the `match` predicate, and all the other types of predicate,
refer to the following sections.

[[search-dsl-predicate-common]]
=== Options common to multiple predicate types
// Search 5 anchors backward compatibility
[[_query_options]]

include::todo-placeholder.asciidoc[]

// TODO boost, constantScore, ...

[[search-dsl-predicate-match-all]]
=== `matchAll`: match all documents

.Matching all documents
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/search/predicate/PredicateDslIT.java[tags=matchAll]
----
====

.Matching all documents except those matching a given predicate
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/search/predicate/PredicateDslIT.java[tags=matchAll-except]
----
====

[[search-dsl-predicate-id]]
=== `id`: match a document identifier

.Matching a document with a given identifier
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/search/predicate/PredicateDslIT.java[tags=id]
----
====

.Matching all documents with an identifier among a given collection
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/search/predicate/PredicateDslIT.java[tags=id-matchingAny]
----
====

[[search-dsl-predicate-match]]
=== `match`: match a value
// Search 5 anchors backward compatibility
[[_keyword_queries]]

.Matching a value
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/search/predicate/PredicateDslIT.java[tags=match]
----
====

.Matching multiple terms
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/search/predicate/PredicateDslIT.java[tags=match-multipleTerms]
----
<1> For full-text fields, the value passed to `matching` may be a string containing multiple terms.
The string will be analyzed and each term identified.
<2> All returned hits will match *at least one* term of the given string.
Hits matching multiple terms will have a higher score.
====

// TODO HSEARCH-917 add an option to match all terms instead of any term, then document it here

.Matching a value in any of multiple fields
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/search/predicate/PredicateDslIT.java[tags=match-orField]
----
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/search/predicate/PredicateDslIT.java[tags=match-fields]
----
====

.Matching a text value approximately
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/search/predicate/PredicateDslIT.java[tags=match-fuzzy]
----
====

// TODO fuzzy parameters: edit distance, prefix length, ...

.Matching a value, analyzing it with a different analyzer
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/search/predicate/PredicateDslIT.java[tags=match-analyzer]
----
====

.Matching a value without analyzing it
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/search/predicate/PredicateDslIT.java[tags=match-skipAnalysis]
----
====

// TODO per-field boosts?

[[search-dsl-predicate-range]]
=== `range`: match a range of values
// Search 5 anchors backward compatibility
[[_range_queries]]

.Matching a range of values
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/search/predicate/PredicateDslIT.java[tags=range-between]
----
====

.Matching values equal to or greater than a given value
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/search/predicate/PredicateDslIT.java[tags=range-atLeast]
----
====

.Matching values strictly greater than a given value
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/search/predicate/PredicateDslIT.java[tags=range-greaterThan]
----
====

.Matching values equal to or less than a given value
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/search/predicate/PredicateDslIT.java[tags=range-atMost]
----
====

.Matching values strictly less than a given value
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/search/predicate/PredicateDslIT.java[tags=range-lessThan]
----
====

.Matching a range of values with explicit bound inclusion/exclusion
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/search/predicate/PredicateDslIT.java[tags=range-between-advanced]
----
====

// TODO multiple fields?

// TODO per-field boosts?

[[search-dsl-predicate-phrase]]
=== `phrase`: match a sequence of words
// Search 5 anchors backward compatibility
[[_phrase_queries]]

.Matching a sequence of words
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/search/predicate/PredicateDslIT.java[tags=phrase]
----
====

.Matching a sequence of words approximately
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/search/predicate/PredicateDslIT.java[tags=phrase-slop]
----
====

// TODO analyzer?

// TODO skipAnalysis?

// TODO multiple fields?

// TODO per-field boosts?

[[search-dsl-predicate-exists]]
=== `exists`: match fields with non-null values

[NOTE]
====
This predicate currently only works with non-object fields.

See https://hibernate.atlassian.net/browse/HSEARCH-2389[HSEARCH-2389].
====

.Matching fields with non-null values
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/search/predicate/PredicateDslIT.java[tags=exists]
----
====

[TIP]
====
There isn't any built-in predicate to match fields with exclusively null values,
but you can easily create one yourself
using an `exists` predicate in a `mustNot` clause in a <<search-dsl-predicate-boolean,boolean predicate>>.
====

[[search-dsl-predicate-wildcard]]
=== `wildcard`: match a simple pattern
// Search 5 anchors backward compatibility
[[_wildcard_queries]]

.Matching a simple pattern
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/search/predicate/PredicateDslIT.java[tags=wildcard]
----
====

[IMPORTANT]
====
If a normalizer has been defined on the field, the patterns used in wildcard predicates
will be normalized.

If an analyzer has been defined on the field:

* when using the Elasticsearch backend, the patterns won't be analyzed nor normalized,
and will be expected to match a *single* indexed token, not a sequence of tokens.
* when using the Lucene backend the patterns will be normalized, but not tokenized:
the pattern will still be expected to match a *single* indexed token, not a sequence of tokens.

For example, a pattern such as `Cat*` could match `cat`
when targeting a field having a normalizer that applies a lowercase filter when indexing.

A pattern such as `john gr*` will not match anything
when targeting a field that tokenizes on spaces.
`gr*` may match, since it doesn't include any space.

When the goal is to match user-provided query strings,
the <<search-dsl-predicate-simple-query-string,simple query string predicate>> should be preferred.
====

[[search-dsl-predicate-boolean]]
=== `bool`: combine predicates (or/and/...)
// Search 5 anchors backward compatibility
[[_combining_queries]]

.Matching a document that matches any of multiple given predicates (~`OR` operator)
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/search/predicate/PredicateDslIT.java[tags=bool-or]
----
<1> The hits *should* have a `title` field matching the text `robot`,
*or* they should match any other clause in the same boolean predicate.
<2> The hits *should* have a `description` field matching the text `investigation`,
*or* they should match any other clause in the same boolean predicate.
<3> All returned hits will match *at least one* of the clauses above:
they will have a `title` field matching the text `robot`
*or* they will have a `description` field matching the text `investigation`.
====

.Matching a document that matches all of multiple given predicates (~`AND` operator)
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/search/predicate/PredicateDslIT.java[tags=bool-and]
----
<1> The hits *must* have a `title` field matching the text `robot`,
independently from other clauses in the same boolean predicate.
<2> The hits *must* have a `description` field matching the text `crime`,
independently from other clauses in the same boolean predicate.
<3> All returned hits will match *all* of the clauses above:
they will have a `title` field matching the text `robot`
*and* they will have a `description` field matching the text `crime`.
====

.Matching a document that does *not* match a given predicate
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/search/predicate/PredicateDslIT.java[tags=bool-mustNot]
----
<1> The hits *must* have a `title` field matching the text `robot`,
independently from other clauses in the same boolean predicate.
<2> The hits *must not* have a `description` field matching the text `investigation`,
independently from other clauses in the same boolean predicate.
<3> All returned hits will match *all* of the clauses above:
they will have a `title` field matching the text `robot`
*and* they will not have a `description` field matching the text `investigation`.

[NOTE]
======
While it is possible to execute a boolean predicate with only "negative" clauses (`mustNot`),
performance may be disappointing because the full power of indexes cannot be leveraged in that case.
======
====

.Matching a document that matches a given predicate without affecting the score
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/search/predicate/PredicateDslIT.java[tags=bool-filter]
----
<1> Create a top-level boolean predicate, with two `should` clauses.
<2> In the first `should` clause, create a nested boolean predicate.
<3> Use a `filter` clause to require documents to have the `science-fiction` genre,
without taking this predicate into account when scoring.
<4> Use a `must` clause to require documents with the `science-fiction` genre
to have a `title` field matching `crime`,
and take this predicate into account when scoring.
<5> In the second `should` clause, create a nested boolean predicate.
<6> Use a `filter` clause to require documents to have the `crime fiction` genre,
without taking this predicate into account when scoring.
<7> Use a `must` clause to require documents with the `crime fiction` genre
to have a `description` field matching `robot`,
and take this predicate into account when scoring.
<8> The score of hits will ignore the `filter` clauses,
leading to fairer sorts if there are much more "crime fiction" documents than "science-fiction" documents.
====

.Using optional `should` clauses to boost the score of some documents
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/search/predicate/PredicateDslIT.java[tags=bool-mustAndShould]
----
<1> The hits *must* have a `title` field matching the text `robot`,
independently from other clauses in the same boolean predicate.
<2> The hits *should* have a `description` field matching the text `crime`,
but they may not, because matching the `must` clause above is enough.
However, matching this `should` clause will improve the score of the document.
<3> The hits *should* have a `description` field matching the text `investigation`,
but they may not, because matching the `must` clause above is enough.
However, matching this `should` clause will improve the score of the document.
<4> All returned hits will match the `must` clause, and optionally the `should` clauses:
they will have a `title` field matching the text `robot`,
and the ones whose description matches either `crime` or `investigation` will have a better score.
====

.Fine-tuning `should` clauses matching requirements with `minimumShouldMatch`
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/search/predicate/PredicateDslIT.java[tags=bool-minimumShouldMatchNumber]
----
<1> At least two "should" clauses must match for this boolean predicate to match.
<2> The hits *should* have a `description` field matching the text `robot`.
<3> The hits *should* have a `description` field matching the text `investigate`.
<4> The hits *should* have a `description` field matching the text `crime`.
<5> All returned hits will match at least two of the `should` clauses:
their description will match either `robot` and `investigate`,
`robot` and `crime`, `investigate` and `crime`, or all three of these terms.
====

.Easily adding clauses dynamically with the lambda syntax
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/search/predicate/PredicateDslIT.java[tags=bool-dynamicParameters]
----
<1> Get a custom object holding the search parameters provided by the user through a web form, for example.
<2> Call `.bool(Consumer)`.
The consumer, implemented by a lambda expression, will receive a builder as an argument
and will add clauses to that builder as necessary.
<3> By default, a boolean predicate will match nothing if there is no clause.
To match every document when there is no clause, add a `must` clause that matches everything.
<4> Inside the lambda, the code is free to check conditions before adding clauses.
In this case, we only add clauses if the relevant parameter was filled in by the user.
<5> The hits will match the clauses added by the lambda expression.
====

[[search-dsl-predicate-simple-query-string]]
=== `simpleQueryString`: match a user-provided query
// Search 5 anchors backward compatibility
[[_simple_query_string_queries]]

.Matching a simple query string: AND/OR operators
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/search/predicate/PredicateDslIT.java[tags=simpleQueryString-boolean]
----
====

.Matching a simple query string: NOT operator
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/search/predicate/PredicateDslIT.java[tags=simpleQueryString-not]
----
====

.Matching a simple query string: AND as default operator
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/search/predicate/PredicateDslIT.java[tags=simpleQueryString-defaultOperator-and]
----
====

.Matching a simple query string: prefix
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/search/predicate/PredicateDslIT.java[tags=simpleQueryString-prefix]
----
====

.Matching a simple query string: fuzzy
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/search/predicate/PredicateDslIT.java[tags=simpleQueryString-fuzzy]
----
====

.Matching a simple query string: phrase
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/search/predicate/PredicateDslIT.java[tags=simpleQueryString-phrase]
----
====

.Matching a simple query string: phrase with slop
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/search/predicate/PredicateDslIT.java[tags=simpleQueryString-phrase-slop]
----
====

// TODO multiple fields?

// TODO per-field boosts?

[[search-dsl-predicate-nested]]
=== `nested`: match nested documents

.Matching a simple pattern
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/search/predicate/PredicateDslIT.java[tags=nested]
----
<1> Create a nested predicate on the `authors` object field.
<2> The author must have a first name matching `isaac`.
<3> The author must have a last name matching `asimov`.
<4> All returned hits will be books for which at least one author
has a first name matching `isaac` and a last name matching `asimov`.
Books that happen to have multiple authors,
one of which has a first name matching `isaac`
and *another* of which has a last name matching `asimov`,
will *not* match.
====

[[search-dsl-predicate-spatial-within]]
=== `within`: match points within a circle, box, polygon
// Search 5 anchors backward compatibility
[[spatial-queries]]

.Matching points within a circle
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/search/predicate/PredicateDslIT.java[tags=within-circle]
----
====

// TODO alternative syntaxes?

.Matching points within a box
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/search/predicate/PredicateDslIT.java[tags=within-box]
----
====

// TODO alternative syntaxes?

.Matching points within a polygon
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/search/predicate/PredicateDslIT.java[tags=within-polygon]
----
====

// TODO alternative syntaxes?

[[search-dsl-predicate-more-like-this]]
=== More like this
[[search-query-querydsl-mlt]]

include::todo-placeholder.asciidoc[]

[[search-dsl-predicate-extensions]]
=== Backend-specific extensions

include::todo-placeholder.asciidoc[]

// TODO introduction to extensions or links to that introduction

[[search-dsl-predicate-extensions-lucene-from-lucene-query]]
==== Lucene: `fromLuceneQuery`

.Matching a native `org.apache.lucene.search.Query`
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/search/predicate/PredicateDslIT.java[tags=lucene-fromLuceneQuery]
----
====

[[search-dsl-predicate-extensions-elasticsearch-from-json]]
==== Elasticsearch: `fromJson`

.Matching a native Elasticsearch JSON query provided as a `JsonObject`
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/search/predicate/PredicateDslIT.java[tags=elasticsearch-fromJson-jsonObject]
----
====

.Matching a native Elasticsearch JSON query provided as a JSON-formatted string
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/search/predicate/PredicateDslIT.java[tags=elasticsearch-fromJson-string]
----
====

[[search-dsl-sort]]
== Sort DSL
// Search 5 anchors backward compatibility
[[query-sorting]]

// TODO add more than just examples in the sub-sections

[[search-dsl-sort-concepts]]
=== Basics

By default, query results are sorted by relevance.
Other sorts, including the sort by field value, can be configured when building the search query:

.Using custom sorts
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/search/sort/SortDslIT.java[tags=entryPoint-lambdas]
----
<1> Start building the query as usual.
<2> Mention that the results of the query are expected to be sorted on field "pageCount" in descending order,
then (for those with the same page count) on field "title_sort" in ascending order.
If the field does not exist or cannot be sorted on, an exception will be thrown.
<3> Fetch the results, which will be sorted according to instructions.
====

Or alternatively, if you don't want to use lambdas:

.Using custom sorts -- object-based syntax
====
[source, JAVA, indent=0]
----
include::{sourcedir}/org/hibernate/search/documentation/search/sort/SortDslIT.java[tags=entryPoint-objects]
----
====

[NOTE]
====
There are a few constraints regarding sorts by field.
In particular, in order for a field to be "sortable", it must be <<mapper-orm-directfieldmapping-sortable,marked as such in the mapping>>,
so that the correct data structures are available in the index.
====

The sort DSL offers more sort types, and multiple options for each type of sort.
To learn more about the field sort, and all the other types of sort,
refer to the following sections.

[[search-dsl-sort-common]]
=== Options common to multiple sort types

include::todo-placeholder.asciidoc[]

// TODO asc(), desc(), order(SortOrder), ...

[[search-dsl-sort-score]]
=== `score`: sort by matching score (relevance)

.Sorting by relevance
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/search/sort/SortDslIT.java[tags=score]
----
====

[[search-dsl-sort-index-order]]
=== `indexOrder`: sort according to the order of documents on storage

.Sorting according to the order of documents on storage
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/search/sort/SortDslIT.java[tags=indexOrder]
----
====

[[search-dsl-sort-field]]
=== `field`: sort by field values

.Sorting by field values
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/search/sort/SortDslIT.java[tags=field]
----
====

// Search 5 anchors backward compatibility
[[_handling_missing_values]]

.Sorting by field values, with missing values in first position
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/search/sort/SortDslIT.java[tags=field-missing-first]
----
====

.Sorting by field values, with missing values in last position
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/search/sort/SortDslIT.java[tags=field-missing-last]
----
====

.Sorting by field values, with missing values replaced by a given value
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/search/sort/SortDslIT.java[tags=field-missing-use]
----
====

[[search-dsl-sort-distance]]
=== `distance`: sort by distance to a point

.Sorting by distance to a point
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/search/sort/SortDslIT.java[tags=distance]
----
====

// TODO alternative syntaxes?

[[search-dsl-sort-composite]]
=== `composite`: combine sorts

.Sorting by multiple composed sorts using `composite()`
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/search/sort/SortDslIT.java[tags=composite]
----
====

.Sorting by multiple composed sorts using `then()`
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/search/sort/SortDslIT.java[tags=then]
----
====

.Easily composing sorts dynamically with the lambda syntax
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/search/sort/SortDslIT.java[tags=composite_dynamicParameters]
----
<1> Get a custom object holding the search parameters provided by the user through a web form, for example.
<2> Call `.composite(Consumer)`.
The consumer, implemented by a lambda expression, will receive a builder as an argument
and will add sorts to that builder as necessary.
<3> Inside the lambda, the code is free to do whatever is necessary before adding sorts.
In this case, we iterate over user-selected sorts and add sorts accordingly.
<4> The hits will be sorted according to sorts added by the lambda expression.
====

[[search-dsl-sort-extensions]]
=== Backend-specific extensions

include::todo-placeholder.asciidoc[]

// TODO introduction to extensions or links to that introduction

[[search-dsl-sort-extensions-lucene-from-lucene-sort]]
==== Lucene: `fromLuceneSort`

.Sorting by a native `org.apache.lucene.search.Sort`
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/search/sort/SortDslIT.java[tags=lucene-fromLuceneSort]
----
====

[[search-dsl-sort-extensions-lucene-from-lucene-sort-field]]
==== Lucene: `fromLuceneSortField`
// Search 5 anchors backward compatibility
[[_using_native_sorts_within_the_sort_dsl]]

.Sorting by a native `org.apache.lucene.search.SortField`
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/search/sort/SortDslIT.java[tags=lucene-fromLuceneSortField]
----
====

[[search-dsl-sort-extensions-elasticsearch-from-json]]
==== Elasticsearch: `fromJson`

.Sorting by a native Elasticsearch JSON sort provided as a `JsonObject`
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/search/sort/SortDslIT.java[tags=elasticsearch-fromJson-jsonObject]
----
====

.Sorting by a native Elasticsearch JSON sort provided as a JSON-formatted string
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/search/sort/SortDslIT.java[tags=elasticsearch-fromJson-string]
----
====

[[search-dsl-projection]]
== Projection DSL
// Search 5 anchors backward compatibility
[[projections]]

// TODO add more than just examples in the sub-sections

[[search-dsl-projection-concepts]]
=== Basics

For some use cases, you only need the query to return a small subset of the data contained in your domain object.
In these cases, returning managed entities and extracting data from these entities may be overkill:
extracting the data from the index itself would avoid the database round-trip.

Projections do just that: they allow the query to return something more precise than just "the matching entities".
Projections can be configured when building the search query:

.Using projections to extract data from the index
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/search/projection/ProjectionDslIT.java[tags=entryPoint-lambdas]
----
<1> Start building the query as usual.
<2> Mention that the expected result of the query is a projection on field "title", of type String.
If that type is not appropriate or if the field does not exist, an exception will be thrown.
<3> Fetch the results, which will have the expected type.
====

Or alternatively, if you don't want to use lambdas:

.Using projections to extract data from the index -- object-based syntax
====
[source, JAVA, indent=0]
----
include::{sourcedir}/org/hibernate/search/documentation/search/projection/ProjectionDslIT.java[tags=entryPoint-objects]
----
====

[NOTE]
====
There are a few constraints regarding field projections.
In particular, in order for a field to be "projectable", it must be <<mapper-orm-directfieldmapping-projectable,marked as such in the mapping>>,
so that it is correctly stored in the index.
====

While field projections are certainly the most common,
they are not the only type of projection.
Other projections allow to
<<search-dsl-projection-composite,compose custom beans containing extracted data>>,
get references to the <<search-dsl-projection-documentReference,extracted documents>>
or the <<search-dsl-projection-reference,corresponding entities>>,
or get information related to the search query itself
(<<search-dsl-projection-score,score>>, ...).

To learn more about the field projection, and all the other types of projection,
refer to the following sections.

[[search-dsl-projection-common]]
=== Options common to multiple projection types

include::todo-placeholder.asciidoc[]

// TODO common options, if there are any?

[[search-dsl-projection-documentReference]]
=== `documentReference`: return references to matched documents

.Returning references to matched documents
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/search/projection/ProjectionDslIT.java[tags=documentReference]
----
====

[[search-dsl-projection-reference]]
=== `entityReference`: return references to matched entities

.Returning references to matched entities
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/search/projection/ProjectionDslIT.java[tags=reference]
----
====

[[search-dsl-projection-entity]]
=== `entity`: return matched entities loaded from the database

.Returning matched entities loaded from the database
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/search/projection/ProjectionDslIT.java[tags=entity]
----
====

[[search-dsl-projection-field]]
=== `field`: return field values from matched documents

.Returning field values from matched documents
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/search/projection/ProjectionDslIT.java[tags=field]
----
====

.Returning field values from matched documents, without specifying the field type
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/search/projection/ProjectionDslIT.java[tags=field-noType]
----
====

.Returning field values from matched documents, without converting the field value
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/search/projection/ProjectionDslIT.java[tags=field-noProjectionConverter]
----
====

[[search-dsl-projection-score]]
=== `score`: return the score of matched documents

.Returning the score of matched documents
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/search/projection/ProjectionDslIT.java[tags=score]
----
====

[[search-dsl-projection-distance]]
=== `distance`: return the distance to a point

.Returning the distance to a point
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/search/projection/ProjectionDslIT.java[tags=distance]
----
====

.Returning the distance to a point with a given distance unit
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/search/projection/ProjectionDslIT.java[tags=distance-unit]
----
====

[[search-dsl-projection-composite]]
=== `composite`: combine projections

.Returning custom objects created from multiple projected values
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/search/projection/ProjectionDslIT.java[tags=composite-customObject]
----
<1> Call `.composite(...)`.
<2> Use the constructor of a custom object, `MyPair`, as the combining function.
The combining function can be a `Function`, a `BiFunction`,
or a `org.hibernate.search.util.common.function.TriFunction`.
It will combine values returned by other projections and create an object returned by the composite projection.
Depending on the type of function,
either one, two, or three additional arguments are expected.
<3> Define the first projection to combine as a projection on the `title` field,
meaning the constructor of `MyPair` will be called for each matched document
with the value of the `title` field as its first argument.
<4> Define the second projection to combine as a projection on the `genre` field,
meaning the constructor of `MyPair` will be called for each matched document
with the value of the `genre` field as its second argument.
<5> The hits will be the result of calling the combining function for each matched document,
in this case `MyPair` instances.
====

.Returning a `List` of projected values
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/search/projection/ProjectionDslIT.java[tags=composite-list]
----
<1> Call `.composite(...)`.
<2> Define the first projection to combine as a projection on the `title` field,
meaning the hits will be `List` instances with the value of the `title` field of the matched document at index `0`.
<3> Define the second projection to combine as a projection on the `genre` field,
meaning the hits will be `List` instances with the value of the `genre` field of the matched document at index `1`.
<4> The hits will be `List` instances holding the result of the given projections, in order for each matched document.
====

[[search-dsl-projection-extensions]]
=== Backend-specific extensions

include::todo-placeholder.asciidoc[]

// TODO introduction to extensions or links to that introduction

[[search-dsl-projection-extensions-lucene-document]]
==== Lucene: `document`

.Returning the matched document as a native `org.apache.lucene.document.Document`
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/search/projection/ProjectionDslIT.java[tags=lucene-document]
----
====

// TODO explain limitations: not the original documents, fields reconstructed from what we find, not all fields presents, ...

[[search-dsl-projection-extensions-lucene-explanation]]
==== Lucene: `explanation`

[WARNING]
====
Explanations are rather costly performance-wise:
only use them for <<search-dsl-query-debugging-scores,debugging>> purposes.
====

.Returning the score explanation as a native `org.apache.lucene.search.Explanation`
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/search/projection/ProjectionDslIT.java[tags=lucene-explanation]
----
====

[[search-dsl-projection-extensions-elasticsearch-source]]
==== Elasticsearch: `source`

.Returning the matched document source as a `JsonObject`
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/search/projection/ProjectionDslIT.java[tags=elasticsearch-source]
----
====

[[search-dsl-projection-extensions-elasticsearch-explanation]]
==== Elasticsearch: `explanation`

[WARNING]
====
Explanations are rather costly performance-wise:
only use them for <<search-dsl-query-debugging-scores,debugging>> purposes.
====

.Returning the score explanation as a `JsonObject`
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/search/projection/ProjectionDslIT.java[tags=elasticsearch-explanation]
----
====

[[search-dsl-projection-extensions-elasticsearch-jsonHit]]
==== Elasticsearch: `jsonHit`

[NOTE]
====
This is particularly useful when <<search-dsl-query-elasticsearch-json,customizing the request's JSON>>
to ask for additional data within each hit.
====

include::components/elasticsearch-request-response-warning.asciidoc[]

.Returning the Elasticsearch hit as a `JsonObject`
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/search/projection/ProjectionDslIT.java[tags=elasticsearch-jsonHit]
----
====

include::todo-placeholder.asciidoc[]
[[search-dsl-aggregation]]
== Aggregation DSL
// Search 5 anchors backward compatibility
[[query-faceting]]

// TODO add more than just examples in the sub-sections

[[search-dsl-aggregation-concepts]]
=== Basics

Sometimes, you don't just need to list query hits directly:
you also need to group and aggregate the hits.

// Search 5 anchors backward compatibility
[[example-amazon-facets]]
For example, almost any e-commerce website you can visit will have some sort of "faceting",
which is a simple form of aggregation.
In the "book search" webpage of an online bookshop, beside the list of matching books,
you will find "facets", i.e. a count of matching documents in various categories.
These categories can be taken directly from the indexed data, e.g. the genre of the book (science-fiction, crime fiction, ...),
but also derived from the indexed data slightly, e.g. a price range ("less than $5", "less than $10", ...).

Aggregations allow just that (and, depending on the backend, much more):
they allow the query to return "aggregated" hits.

// Search 5 anchors backward compatibility
[[section-creating-faceting-request]][[section-applying-faceting-request]]
Aggregations can be configured when building the search query:

// Search 5 anchors backward compatibility
[[example-applying-faceting]]
.Defining an aggregation in a search query
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/search/aggregation/AggregationDslIT.java[tags=entryPoint-lambdas]
----
<1> Define a key that will uniquely identify the aggregation. Make sure to give it the correct type (see <6>).
<2> Start building the query as usual.
<3> Define a predicate: the aggregation will only take into account documents matching this predicate.
<4> Request an aggregation on the `genre` field,
with a separate count for each genre: science-fiction, crime fiction, ...
If the field does not exist or cannot be aggregated, an exception will be thrown.
<5> Fetch the results.
<6> Retrieve the aggregation from the results as a `Map`,
with the genre as key and the hit count as value of type `Long`.
====

Or alternatively, if you don't want to use lambdas:

.Defining an aggregation in a search query -- object-based syntax
====
[source, JAVA, indent=0]
----
include::{sourcedir}/org/hibernate/search/documentation/search/aggregation/AggregationDslIT.java[tags=entryPoint-objects]
----
====

// Search 5 anchors backward compatibility
[[example-faceting-entity]]
[NOTE]
====
There are a few constraints regarding aggregations.
In particular, in order for a field to be "aggregable", it must be <<mapper-orm-directfieldmapping-aggregable,marked as such in the mapping>>,
so that it is correctly stored in the index.
====

// Search 5 anchors backward compatibility
[[example-restricting-query-results]]
[TIP]
====
Faceting generally involves a concept of "drill-down",
i.e. the ability to select a facet and restrict the hits
to only those that match that facet.

Hibernate Search 5 used to offer a dedicated API to enable this "drill-down",
but in Hibernate Search 6 you should simply create a new query
with the appropriate <<search-dsl-predicate,predicate>>.
====

The aggregation DSL offers more aggregation types, and multiple options for each type of aggregation.
To learn more about the `terms` aggregation, and all the other types of aggregations,
refer to the following sections.

[[search-dsl-aggregation-terms]]
=== `terms`: group by the value of a field
// Search 5 anchors backward compatibility
[[discrete-faceting-request]]

// TODO introduction, mention default order, default minDocCount, default maxTermCount

.Counting hits grouped by the value of a field
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/search/aggregation/AggregationDslIT.java[tags=terms]
----
<1> Define the path and type of the field whose values should be considered.
====

.Counting hits grouped by the value of a field, without converting field values
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/search/aggregation/AggregationDslIT.java[tags=terms-noConverter]
----
====

.Setting the maximum number of returned entries in a `terms` aggregation
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/search/aggregation/AggregationDslIT.java[tags=terms-max-term-count]
----
====

.Including values from unmatched documents in a `terms` aggregation
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/search/aggregation/AggregationDslIT.java[tags=terms-min-doc-count-zero]
----
====

.Excluding the rarest terms from a `terms` aggregation
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/search/aggregation/AggregationDslIT.java[tags=terms-min-doc-count-high]
----
====

[WARNING]
====
With the Lucene backend, due to limitations of the current implementation,
using any order other than the default one (by descending count)
may lead to incorrect results.
See https://hibernate.atlassian.net/browse/HSEARCH-3666[HSEARCH-3666] for more information.
====

// Search 5 anchors backward compatibility
[[section-sorting-faceting-request]]
.Ordering entries by ascending value in a `terms` aggregation
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/search/aggregation/AggregationDslIT.java[tags=terms-order-term-ascending]
----
====

.Ordering entries by descending value in a `terms` aggregation
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/search/aggregation/AggregationDslIT.java[tags=terms-order-term-descending]
----
====

.Ordering entries by ascending count in a `terms` aggregation
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/search/aggregation/AggregationDslIT.java[tags=terms-order-count-ascending]
----
====

[WARNING]
====
When ordering entries by ascending count in a `terms` aggregation,
link:{elasticsearchDocUrl}/search-aggregations-bucket-terms-aggregation.html#search-aggregations-bucket-terms-aggregation-order[hit counts are approximate].
====

[[search-dsl-aggregation-range]]
=== `range`: grouped by ranges of values for a field
// Search 5 anchors backward compatibility
[[range-faceting-request]]

// TODO introduction, mention default order

[NOTE]
====
Range aggregations are not available on String-based fields.
====

.Counting hits grouped by range of values for a field
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/search/aggregation/AggregationDslIT.java[tags=range]
----
<1> Define the path and type of the field whose values should be considered.
<2> Define the ranges to group hits into.
The range can be passed directly as the lower bound (included) and upper bound (excluded).
Other syntaxes exist to define different bound inclusion (see other examples below).
<3> `null` means "to infinity".
====

.Counting hits grouped by range of values for a field -- passing `Range` objects
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/search/aggregation/AggregationDslIT.java[tags=range-objects]
----
<1> With `Range.of(Object, Object)`, the lower bound is included and the upper bound is excluded.
<2> `Range.of(Object, RangeBoundInclusion, Object, RangeBoundInclusion)` is more verbose, but allows setting the bound inclusion explicitly.
<3> `Range` also offers multiple static methods to create ranges for a variety of use cases ("at least", "greater than", "at most", ...).
====

[WARNING]
====
With the Elasticsearch backend, due to a limitation of Elasticsearch itself,
all ranges must have their lower bound included (or `null`)
and their upper bound excluded (or `null`).
Otherwise, an exception will be thrown.

If you need to exclude the lower bound, or to include the upper bound,
replace that bound with the immediate next value instead.
For example with integers, `.range( 0, 100 )` means "0 (included) to 100 (excluded)".
Call `.range( 0, 101 )` to mean "0 (included) to 100 (included)",
or `.range( 1, 100 )` to mean "0 (excluded) to 100 (excluded)".
====

.Counting hits grouped by range of values for a field, without converting field values
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/search/aggregation/AggregationDslIT.java[tags=range-noConverter]
----
====

[[search-dsl-aggregation-extensions]]
=== Backend-specific extensions

include::todo-placeholder.asciidoc[]

// TODO introduction to extensions or links to that introduction

[[search-dsl-aggregation-extensions-elasticsearch-from-json]]
==== Elasticsearch: `fromJson`

.Defining a native Elasticsearch JSON aggregation as a `JsonObject`
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/search/aggregation/AggregationDslIT.java[tags=elasticsearch-fromJson-jsonObject]
----
<1> The aggregation result is a `JsonObject`.
====

.Defining a native Elasticsearch JSON aggregation as a JSON-formatted string
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/search/aggregation/AggregationDslIT.java[tags=elasticsearch-fromJson-string]
----
<1> The aggregation result is a `JsonObject`.
====

[[search-dsl-type-compatibility]]
== Field types and compatibility

[[search-dsl-argument-type]]
=== Type of arguments passed to the DSL

Some predicates, such as the `match` predicate or the `range` predicate,
require a parameter of type `Object` at some point (`matching(Object)`, `atLeast(Object)`, ...).
Similarly, it is possible to pass an argument of type `Object` in the sort DSL
when defining the behavior for missing values (`missing().use(Object)`).

These methods do not actually accept *any* object,
and will throw an exception when passed an argument with the wrong type.

Generally the expected type of this argument should be rather obvious:
for example if you created a field by mapping an `Integer` property,
then an `Integer` value will be expected when building a predicate;
if you mapped a `java.time.LocalDate`, then a `java.time.LocalDate` will be expected,
etc.

Things get a little more complex if you start defining and using custom bridges.
You will then have properties of type `A` mapped to an index field of type `B`.
What should you pass to the DSL?
To answer that question, we need to understand DSL converters.

DSL converters are a feature of Hibernate Search that allows the DSL to accept
arguments that match the type of the indexed property,
instead of the type of the underlying index field.

Each custom bridge has the possibility to define a DSL converter for the index fields it populates.
When it does, every time that field is mentioned in the predicate DSL,
Hibernate Search will use that DSL converter to convert the value passed to the DSL to a value that the backend understands.

For example, let's imagine an `AuthenticationEvent` entity with an `outcome` property of type `AuthenticationOutcome`.
This `AuthenticationOutcome` type is an enum.
We index the `AuthenticationEvent` entity and its `outcome` property in order to allow users to find events by their outcome.

The default bridge for enums puts the result of `Enum.name()` into a `String` field.
However, this default bridge also defines a DSL converter under the hood.
As a result, any call to the DSL will be expected to pass an `AuthenticationOutcome` instance:

.Transparent conversion of DSL parameters
====
[source, JAVA, indent=0]
----
include::{sourcedir}/org/hibernate/search/documentation/search/converter/DslConverterIT.java[tags=dsl-converter-enabled]
----
====

This is handy, and especially appropriate if users are asked to select an outcome in a list of choices.
But what if we want users to type in some words instead, i.e. what if we want full-text search on the `outcome` field?
Then we will not have an `AuthenticationOutcome` instance to pass to the DSL, only a `String`...

In that case, we will first need to assign some text to each enum.
This can be achieved by defining a custom <<mapper-orm-bridge-valuebridge,`ValueBridge<AuthenticationOutcome, String>`>>
and applying it to the `outcome` property so as to index a textual description of the outcome,
instead of the default `Enum#name()`.

Then, we will need to tell Hibernate Search that the value passed to the DSL should not be passed to the DSL converter,
but should be assumed to match the type of the index field directly (in this case, `String`).
To that end, one can simply use the variant of the `matching` method that accepts a `ValueConvert` parameter,
and pass `ValueConvert.NO`:

.Disabling the DSL converter
====
[source, JAVA, indent=0]
----
include::{sourcedir}/org/hibernate/search/documentation/search/converter/DslConverterIT.java[tags=dsl-converter-disabled]
----
====

All methods that apply DSL converters offer a variant that accepts a `ValueConvert` parameter:
`matching`, `between`, `atLeast`, `atMost`, `greaterThan`, `lessThan`, `range`, ...

[NOTE]
====
A DSL converter is always automatically generated for value bridges.
However, more complex bridges will require explicit configuration.

See <<mapper-orm-bridge-typebridge>> or <<mapper-orm-bridge-propertybridge>> for more information.
====

[[search-dsl-projected-value-type]]
=== Type of projected values

Generally the type of values returned by projections argument should be rather obvious:
for example if you created a field by mapping an `Integer` property,
then an `Integer` value will be returned when projecting;
if you mapped a `java.time.LocalDate`, then a `java.time.LocalDate` will be returned,
etc.

Things get a little more complex if you start defining and using custom bridges.
You will then have properties of type `A` mapped to an index field of type `B`.
What will be returned by projections?
To answer that question, we need to understand projection converters.

Projection converters are a feature of Hibernate Search that allows the projections to return
values that match the type of the indexed property,
instead of the type of the underlying index field.

Each custom bridge has the possibility to define a projection converter for the index fields it populates.
When it does, every time that field is projected on,
Hibernate Search will use that projection converter to convert the projected value returned by the index.

For example, let's imagine an `Order` entity with a `status` property of type `OrderStatus`.
This `OrderStatus` type is an enum.
We index the `Order` entity and its `status` property.

The default bridge for enums puts the result of `Enum.name()` into a `String` field.
However, this default bridge also defines a projection converter.
As a result, any projection on the `status` field will return an `OrderStatus` instance:

.Transparent conversion of projections
====
[source, JAVA, indent=0]
----
include::{sourcedir}/org/hibernate/search/documentation/search/converter/ProjectionConverterIT.java[tags=projection-converter-enabled]
----
====

This is probably what you want in general.
But in some cases, you may want to disable this conversion and return the index value instead
(i.e. the value of `Enum.name()`).

In that case, we will need to tell Hibernate Search that the value returned by the backend should not be passed to the projection converter.
To that end, one can simply use the variant of the `field` method that accepts a `ValueConvert` parameter,
and pass `ValueConvert.NO`:

.Disabling the projection converter
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/search/converter/ProjectionConverterIT.java[tags=projection-converter-disabled]
----
====

[NOTE]
====
Projection converters must be configured explicitly in custom bridges.

See <<mapper-orm-bridge-valuebridge>>,
<<mapper-orm-bridge-propertybridge>> or <<mapper-orm-bridge-typebridge>> for more information.
====

[[search-dsl-multiple-fields]]
=== Targeting multiple fields

Sometimes a predicate/sort/projection targets *multiple* field, which may have conflicting definitions:

* when multiple field names are passed to the `fields` method in the predicate DSL (each field has its own definition);
* or when the search query <<search-dsl-query-targeting-multiple,targets multiple indexes>> (each index has its own definition of each field).

In such cases, the definition of the targeted fields is expected to be compatible.
For example targeting an `Integer` field and a `java.time.LocalDate` field
in the same `match` predicate will not work,
because you won't be able to pass a non-null argument to the `matching(Object)` method
that is both an `Integer` and a `java.time.LocalDate`.

If you are looking for a simple rule of thumb, here it is:
if the indexed properties do not have the same type, or are mapped differently,
the corresponding fields are probably not going to be compatible.

However, if you're interested in the details, Hibernate Search is a bit more flexible than that.

There are three different constraints when it comes to field compatibility:

1. The fields must be "encoded" in a compatible way.
This means the backend must use the same representation for the two fields,
for example they are both `Integer`,
or they are both `BigDecimal` with the same decimal scale,
or they are both `LocalDate` with the same date format, etc.
2. The fields must have a compatible DSL converter (for predicates and sorts) or projection converter (for projections).
3. For full-text predicates, the fields must have a compatible analyzer.

The following sections describe all the possible incompatibilities, and how to solve them.

==== Incompatible codec

In a search query targeting multiple indexes,
if a field is encoded differently in each index,
you cannot apply predicates, sorts or projections on that field.

NOTE: Encoding is not only about the field type, such as `LocalDate` or `BigDecimal`.
Some codecs are parameterized and two codecs with different parameters will often be considered incompatible.
Examples of parameters include the format for temporal types
or the <<mapper-orm-directfieldmapping-annotations-scalednumberfield, decimal scale>>
for `BigDecimal` and `BigInteger`.

In that case, your only option is to change your mapping to avoid the conflict:

1. rename the field in one index
2. OR change the field type in one index
3. OR if the problem is simply different codec parameters (date format, decimal scale, ...),
align the value of these parameters in one index with the other index.

If you choose to rename the field in one index,
you will still be able to apply a similar predicate
to the two fields in a single query:
you will have to create one predicate per field
and combine them with a <<search-dsl-predicate-boolean,boolean junction>>.

==== Incompatible DSL converters

Incompatible DSL converters are only a problem when you need to pass an argument to the DSL in certain methods:
`matching(Object)`/`between(Object)`/`atLeast(Object)`/`greaterThan(Object)`/etc. in the predicate DSL,
`missing().use(Object) in the sort DSL,
`range(Object, Object)` in the aggregation DSL,
...

If two fields encoded in a compatible way (for example both as `String`),
but that have different DSL converters
(for example the first one converts from `String` to `String`, but the second one converts from `Integer` to `String`),
you can still use these methods, but you will need to disable the DSL converter
as explained in <<search-dsl-argument-type>>:
you will just pass the "index" value to the DSL (using the same example, a `String`).

==== Incompatible projection converters

If, in a search query targeting multiple indexes,
a field is encoded in a compatible way in every indexes (for example both as `String`),
but that has a different projection converters
(for example the first one converts from `String` to `String`, but the second one converts from `String` to `Integer`),
you can still project on this field, but you will need to disable the projection converter
as explained in <<search-dsl-projected-value-type>>:
the projection will return the "index", unconverted value (using the same example, a `String`).

==== Incompatible analyzer

Incompatible analyzers are only a problem with full-text predicates:
match predicate on a text field, phrase predicate, simple query string predicate, ...

If two fields encoded in a compatible way (for example both as `String`),
but that have different analyzers,
you can still use these predicates, but you will need to explicitly configure the predicate to either
set the search analyzer to an analyzer of your choosing with `.analyzer(analyzerName)`,
or skip analysis completely with `.skipAnalysis()`.

See <<search-dsl-predicate>> for more information about how to create predicates
and about the available options.
