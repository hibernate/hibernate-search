[[backend-elasticsearch]]
= Elasticsearch backend
// Search 5 anchors backward compatibility
[[elasticsearch-integration]]

include::todo-placeholder.asciidoc[]

[[backend-elasticsearch-compatibility]]
== Compatibility

include::todo-placeholder.asciidoc[]
// TODO HSEARCH-3262 Document upgrade policy, for how long we'll support each version, etc. Maybe just a link to a dedicated section on the website?

Hibernate Search expects an Elasticsearch cluster running version 5.6, 6.x or 7.x.
The version running on your cluster will be automatically detected on startup,
and Hibernate Search will adapt based on the detected version;
see <<backend-elasticsearch-configuration-version>> for details.

The targeted version is mostly transparent to Hibernate Search users,
but there are a few differences in how Hibernate Search behaves depending
on the Elasticsearch version that may affect you.
The following table details those differences.

[cols="h,3*",options="header"]
|===============
||5.6|6.x|7.x
|Formats for date fields in the Elasticsearch schema 3+|Formats changed in ES 7, see <<backend-elasticsearch-field-types>>
|`indexNullAs` on `geo_point` fields |Not available 2+|Available
|===============

=== Upgrading Elasticsearch

When upgrading your Elasticsearch cluster, some
https://www.elastic.co/guide/en/elasticsearch/reference/current/setup-upgrade.html[administrative tasks]
are still required on your cluster: Hibernate Search will not take care of those.

On top of that, there are some fundamental differences between some versions of Elasticsearch:
for example date formats changed in Elasticsearch 7,
meaning the schema defined in Elasticsearch 6 may not be compatible
with the one expected by Hibernate Search for Elasticsearch 7.

In such cases, the easiest way to upgrade is to delete your indexes manually,
make Hibernate Search re-create the indexes along with their schema,
and <<mapper-orm-indexing-massindexer,reindex your data>>.

[[backend-elasticsearch-configuration]]
== Basic configuration
// Search 5 anchors backward compatibility
[[elasticsearch-integration-configuration]]

In order to define an Elasticsearch backend,
the `hibernate.search.backends.<backend name>.type` property must be set to `elasticsearch`.

All other configuration properties are optional,
but the defaults might not suit everyone.
In particular your production Elasticsearch cluster is probably not reachable at `http://localhost:9200`,
so you will need to set the address of your cluster by <<backend-elasticsearch-configuration-client,configuring the client>>.

Configuration properties are mentioned in the relevant parts of this documentation.
You can find a full reference of available properties in the Hibernate Search javadoc:

* link:{hibernateSearchJavadocUrl}/org/hibernate/search/backend/elasticsearch/cfg/ElasticsearchBackendSettings.html[org.hibernate.search.backend.elasticsearch.cfg.ElasticsearchBackendSettings].
* link:{hibernateSearchJavadocUrl}/org/hibernate/search/backend/elasticsearch/cfg/ElasticsearchIndexSettings.html[org.hibernate.search.backend.elasticsearch.cfg.ElasticsearchIndexSettings].

== Configuration of the Elasticsearch cluster
// Search 5 anchors backward compatibility
[[elasticsearch-integration-server-configuration]]

Most of the time, Hibernate Search does not require any specific configuration
to be applied by hand to the Elasticsearch cluster,
beyond the index mapping (schema)
which <<mapper-orm-schema-management,can be automatically generated>>.

The only exception is <<backend-elasticsearch-configuration-sharding>>,
which needs to be enabled explicitly.

[[backend-elasticsearch-configuration-client]]
== Client configuration

An Elasticsearch backend communicates with an Elasticsearch cluster through a REST client.
Below are the options that affect this client.

=== Target hosts

The following property configures the Elasticsearch host (or hosts)
to send indexing requests and search queries to:

[source]
----
hibernate.search.backends.<backend name>.hosts = localhost:9200 (default)
----

This property may be set to a String representing a host and port such as `localhost` or `es.mycompany.com:4400`,
or a String containing multiple such host-and-port strings separated by commas,
or a `Collection<String>` containing such host-and-port strings.

You may change the protocol used to communicate with the hosts using this configuration property:

[source]
----
hibernate.search.backends.<backend name>.protocol = http (default)
----

This property may be set to either `http` or `https`.

[[backend-elasticsearch-configuration-discovery]]
=== Node discovery

When using automatic discovery, the Elasticsearch client will periodically probe for new nodes in the cluster,
and will add those to the host list (see `hosts` in <<backend-elasticsearch-configuration-client>>).

Automatic discovery is controlled by the following properties:

[source]
----
hibernate.search.backends.<backend name>.discovery.enabled = false (default)
hibernate.search.backends.<backend name>.discovery.refresh_interval = 10 (default)
----

* `discovery.enabled` defines whether the feature is enabled.
Expects a boolean value.
* `discovery.refresh_interval` defines the interval between two executions of the automatic discovery.
Expects a positive integer, in seconds.

[[backend-elasticsearch-authentication-http]]
=== HTTP authentication

HTTP authentication is disabled by default,
but may be enabled by setting the following configuration properties:

[source]
----
hibernate.search.backends.<backend name>.username = ironman (default is empty)
hibernate.search.backends.<backend name>.password = j@rv1s (default is empty)
----

The username and password to send when connecting to the Elasticsearch servers.

[CAUTION]
====
If you use HTTP instead of HTTPS (see above),
your password will be transmitted in clear text over the network.
====

[[backend-elasticsearch-configuration-aws]]
=== Authentication on Amazon Web Services
// Search 5 anchors backward compatibility
[[elasticsearch-integration-configuration-aws]]

The Hibernate Search Elasticsearch backend, once configured, will work just fine in most setups.
However, if you need to use Amazon's https://docs.aws.amazon.com/elasticsearch-service/[managed Elasticsearch service],
you will find it requires a proprietary authentication method:
https://docs.aws.amazon.com/elasticsearch-service/latest/developerguide/es-request-signing.html[request signing].

While request signing is not supported by default,
you can enable it with an additional dependency and a little bit of configuration.

You will need to add this dependency:

[source, XML, subs="+attributes"]
----
<dependency>
   <groupId>org.hibernate</groupId>
   <artifactId>hibernate-search-backend-elasticsearch-aws</artifactId>
   <version>{hibernateSearchVersion}</version>
</dependency>
----

With that dependency in your classpath,
Hibernate Search will be able to understand the following configuration properties.

[source]
----
hibernate.search.backends.<backend name>.aws.signing.enabled = false (default)
hibernate.search.backends.<backend name>.aws.signing.access_key = AKIDEXAMPLE (no default)
hibernate.search.backends.<backend name>.aws.signing.secret_key = wJalrXUtnFEMI/K7MDENG+bPxRfiCYEXAMPLEKEY (no default)
hibernate.search.backends.<backend name>.aws.signing.region = us-east-1 (no default)
----

* `aws.signing.enabled` defines whether request signing is enabled.
Expects a boolean value.
* `aws.signing.access_key` defines the access key.
Expects a string value.
This property has no default and must be provided for the AWS authentication to work.
* `aws.signing.secret_key` defines the secret key.
Expects a string value.
This property has no default and must be provided for the AWS authentication to work.
* `aws.signing.region` defines the AWS region.
Expects a string value.
This property has no default and must be provided for the AWS authentication to work.

[TIP]
====
Should you need help with finding the correct values for these properties,
please refer to the AWS documentation related to http://docs.aws.amazon.com/general/latest/gr/aws-security-credentials.html[security credentials]
and http://docs.aws.amazon.com/general/latest/gr/rande.html[regions].
====

=== Connection tuning

Timeouts::
+
[source]
----
hibernate.search.backends.<backend name>.request_timeout = 60000 (default)
hibernate.search.backends.<backend name>.connection_timeout = 3000 (default)
hibernate.search.backends.<backend name>.read_timeout = 60000 (default)
----

* `request_timeout` defines the timeout when executing a request.
This includes the time needed to establish a connection,
send the request and read the response.
* `connection_timeout` defines the timeout when establishing a connection.
* `read_timeout` defines the timeout when reading a response.

+
These properties expect a positive <<configuration-property-types,Integer value>> in milliseconds, such as `3000`.

Connection pool::
+
[source]
----
hibernate.search.backends.<backend name>.max_connections = 20 (default)
hibernate.search.backends.<backend name>.max_connections_per_route = 10 (default)
----

* `max_connections` defines maximum number of simultaneous connections
to the Elasticsearch cluster, all hosts taken together.
* `max_connections_per_route` defines maximum number of simultaneous connections
to each host of the Elasticsearch cluster.

+
These properties expect a positive <<configuration-property-types,Integer value>>, such as `20`.

[[backend-elasticsearch-configuration-version]]
=== Version
// Keep the old anchor to avoid dead links
[[backend-elasticsearch-configuration-dialect]]

Different versions of Elasticsearch expose slightly different APIs.
As a result, Hibernate Search needs to be aware of the version of Elasticsearch it is talking to
in order to generate correct HTTP requests.

By default, Hibernate Search will query the Elasticsearch cluster at boot time to know its version,
and will infer the correct behavior to adopt.

If necessary, you can disable the call to the Elasticsearch cluster for version checks on startup.
To do that, set `hibernate.search.backends.<backend name>.version_check.enabled` to `false`,
and set the property `hibernate.search.backends.<backend name>.version`
to a string following the format `x.y.z-qualifier`,
where `x`, `y` and `z` are integers
and `qualifier` is an optional string of word characters (alphanumeric or `_`).

The major and minor version numbers (`x` and `y` in the format above) are mandatory,
but other numbers are optional.

[TIP]
====
The property `hibernate.search.backends.<backend name>.version` can also be set
when `hibernate.search.backends.<backend name>.version_check.enabled` is `true` (the default).

In that case,
Hibernate Search will still query the Elasticsearch cluster to know the actual version of the cluster,
and will check that the configured version matches the actual version.
This can be helpful while developing, in particular.
====

[[backend-elasticsearch-configuration-logging]]
=== Logging
// Search 5 anchors backward compatibility
[[elasticsearch-log-json-pretty-printing]]

The `hibernate.search.backends.<backend name>.log.json_pretty_printing` <<configuration-property-types,boolean property>>
defines whether JSON included in logs should be pretty-printed (indented, with line breaks).
It defaults to `false`.

[[backend-elasticsearch-configuration-sharding]]
== Sharding

include::components/sharding-intro-note.asciidoc[]

Elasticsearch disables sharding by default.
To enable it,
link:{elasticsearchDocUrl}/index-modules.html#_static_index_settings[set the property `index.number_of_shards` in your cluster].

[[backend-elasticsearch-index-lifecycle]]
== Index lifecycle
// Search 5 anchors backward compatibility
[[elasticsearch-schema-management-strategy]]

Elasticsearch indexes need to be created before they can be used for indexing and searching;
see <<mapper-orm-schema-management>> for more information about how to create indexes and their schema
in Hibernate Search.

For Elasticsearch specifically, some fine-tuning is available through the following options:

[source]
----
hibernate.search.backends.<backend name>.indexes.<index name>.schema_management.minimal_required_status green (default)
hibernate.search.backends.<backend name>.indexes.<index name>.schema_management.minimal_required_status_wait_timeout 10000 (default)
# OR
hibernate.search.backends.<backend name>.index_defaults.schema_management.minimal_required_status green (default)
hibernate.search.backends.<backend name>.index_defaults.schema_management.minimal_required_status_wait_timeout 10000 (default)
----

* `minimal_required_status` defines the minimal required status of an index before creation is considered complete.
* `minimal_required_status_wait_timeout` defines the maximum time to wait for this status,
as an <<configuration-property-types,integer value>> in milliseconds.

These properties are only effective when creating or validating an index as part of schema management.

[[backend-elasticsearch-indexlayout]]
== Index layout

Hibernate Search works with link:{elasticsearchDocUrl}/indices-aliases.html[aliased] indexes.
This means an index with a given name in Hibernate Search will not directly be mapped
to an index with the same name in Elasticsearch.

By default, for an index whose name in Hibernate Search is `myIndex`:

* Write operations (indexing, purge, ...) will target the alias `myindex-write`.
* Read operations (searching, explaining, ...) will target the alias `myindex-read`.
* If Hibernate Search <<backend-elasticsearch-index-lifecycle,creates the index automatically>>,
it will name the index `myindex-000001` and will automatically create the write and read aliases.

[TIP]
====
This layout is a bit more complex than it could be, but it follows the best practices.

Using aliases has a significant advantage over directly targeting the index:
it makes full reindexing on a live application possible.
With aliases, you just need to direct the read alias (used by search queries) to an old copy of the index,
while the write alias (used by document writes) is redirected to a new copy of the index.

This "zero-downtime" reindexing,
which shares some characteristics with link:https://martinfowler.com/bliki/BlueGreenDeployment.html["blue/green" deployment],
is not currently provided by Hibernate Search itself.
However, you can implement it in your application
by directly issuing commands to Elasticsearch's REST APIs.
The basic sequence of actions is the following:

1. Create a new index, `myindex-000002`.
2. Switch the write alias, `myindex-write`, from `myindex-000001` to `myindex-000002`.
3. Reindex, for example using the <<mapper-orm-indexing-massindexer,mass indexer>>.
4. Switch the read alias, `myindex-read`, from `myindex-000001` to `myindex-000002`.
5. Delete `myindex-000001`.
====

If the default names and aliases used by Hibernate Search do not match your needs,
you can define a custom layout in two simple steps:

1. Define a class that implements the interface `org.hibernate.search.backend.elasticsearch.index.layout.IndexLayoutStrategy`.
2. Configure the backend to use that implementation by setting the configuration property
`hibernate.search.backends.<backend name>.layout.strategy`
to a <<configuration-property-types,bean reference>> pointing to the implementation.

For example, the implementation below will lead to the following layout for an index named `myIndex`:

* Write operations (indexing, purge, ...) will target the alias `myindex-write`.
* Read operations (searching, explaining, ...) will target the alias `myindex` (no suffix).
* If Hibernate Search <<backend-elasticsearch-index-lifecycle,creates the index automatically>>
at exactly 19:19:00 on November 6th, 2017,
it will name the index `myindex-20171106-191900-000000000`.

.Implementing a custom index layout strategy with the Elasticsearch backend
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/backend/elasticsearch/layout/CustomLayoutStrategy.java[tags=include]
----
====

[[backend-elasticsearch-schema]]
== Schema ("mapping")

What Elasticsearch calls the link:{elasticsearchDocUrl}/mapping.html["mapping"]
is the schema assigned to each index,
specifying the data type and capabilities of each "property" (called an "index field" in Hibernate Search).

For the most part, the Elasticsearch mapping is inferred from
<<mapper-orm-mapping,the mapping configured through Hibernate Search's mapping APIs>>,
which are generic and independent from Elasticsearch.

Aspects that are specific to the Elasticsearch backend are explained in this section.

[TIP]
====
Hibernate Search can be configured to push the mapping to Elasticsearch when creating the indexes
through the <<backend-elasticsearch-index-lifecycle,index lifecycle strategy>>.
====

[[backend-elasticsearch-field-types]]
=== Field types

[[backend-elasticsearch-field-types-available]]
==== Available field types

[NOTE]
====
Some types are not supported directly by the Elasticsearch backend,
but will work anyway because they are "bridged" by the mapper.
For example a `java.util.Date` in your entity model is "bridged" to `java.time.Instant`,
which is supported by the Elasticsearch backend.
See <<mapper-orm-directfieldmapping-supported-types>> for more information.
====

[NOTE]
====
Field types that are not in this list can still be used with a little bit more work:

* If a property in the entity model has an unsupported type,
but can be converted to a supported type, you will need a bridge.
See <<mapper-orm-bridge>>.
* If you need an index field with a specific type that is not supported by Hibernate Search,
you will need a bridge that defines a native field type.
See <<backend-elasticsearch-field-types-extension>>.
====

[cols="l,1,1",options="header"]
.Field types supported by the Elasticsearch backend
|====
|Field type|link:{elasticsearchDocUrl}/mapping-types.html[Data type] in Elasticsearch|Limitations
|java.lang.String|`text` if an analyzer is defined, `keyword` otherwise|-
|java.lang.Byte|`byte`|-
|java.lang.Short|`short`|-
|java.lang.Integer|`integer`|-
|java.lang.Long|`long`|-
|java.lang.Double|`double`|-
|java.lang.Float|`float`|-
|java.lang.Boolean|`boolean`|-
|java.math.BigDecimal
 |`scaled_float` with a `scaling_factor` equal to 10^(`decimalScale`)
 |-
|java.math.BigInteger
 |`scaled_float` with a `scaling_factor` equal to 10^(`decimalScale`)
 |-
|java.time.Instant
 |`date` with format `uuuu-MM-dd'T'HH:mm:ss.SSSSSSSSSZZZZZ` (ES7 and above)
 or `yyyy-MM-dd'T'HH:mm:ss.SSS'Z'\|\|yyyyyyyyy-MM-dd'T'HH:mm:ss.SSSSSSSSS'Z'` (ES6 and below)
 |<<backend-elasticsearch-field-types-date-time>>
|java.time.LocalDate
 |`date` with format `uuuu-MM-dd` (ES7 and above)
 or `yyyy-MM-dd\|\|yyyyyyyyy-MM-dd` (ES6 and below)
 |<<backend-elasticsearch-field-types-date-time>>
|java.time.LocalTime
 |`date` with format `HH:mm:ss.SSSSSSSSS` (ES7 and above)
 or `HH:mm:ss.SSS\|\|HH:mm:ss.SSSSSSSSS` (ES6 and below)
 |<<backend-elasticsearch-field-types-date-time>>
|java.time.LocalDateTime
 |`date` with format `uuuu-MM-dd'T'HH:mm:ss.SSSSSSSSS` (ES7 and above)
 or `yyyy-MM-dd'T'HH:mm:ss.SSS\|\|yyyyyyyyy-MM-dd'T'HH:mm:ss.SSSSSSSSS` (ES6 and below)
 |<<backend-elasticsearch-field-types-date-time>>
|java.time.ZonedDateTime
 |`date` with format `uuuu-MM-dd'T'HH:mm:ss.SSSSSSSSSZZZZZ'['VV']'` (ES7 and above)
 or `yyyy-MM-dd'T'HH:mm:ss.SSSZZ'['ZZZ']'\|\|yyyyyyyyy-MM-dd'T'HH:mm:ss.SSSSSSSSSZZ'['ZZZ']'\|\|yyyyyyyyy-MM-dd'T'HH:mm:ss.SSSSSSSSSZZ'['ZZ']'` (ES6 and below)
 |<<backend-elasticsearch-field-types-date-time>>
|java.time.OffsetDateTime
 |`date` with format `uuuu-MM-dd'T'HH:mm:ss.SSSSSSSSSZZZZZ` (ES7 and above)
 or `yyyy-MM-dd'T'HH:mm:ss.SSSZZ\|\|yyyyyyyyy-MM-dd'T'HH:mm:ss.SSSSSSSSSZZ` (ES6 and below)
 |<<backend-elasticsearch-field-types-date-time>>
|java.time.OffsetTime
 |`date` with format `HH:mm:ss.SSSSSSSSSZZZZZ` (ES7 and above)
 or `HH:mm:ss.SSSZZ\|\|HH:mm:ss.SSSSSSSSSZZ` (ES6 and below)
 |<<backend-elasticsearch-field-types-date-time>>
|java.time.Year
 |`date` with format `uuuu` (ES7 and above)
 or `yyyy\|\|yyyyyyyyy` (ES6 and below)
 |<<backend-elasticsearch-field-types-date-time>>
|java.time.YearMonth
 |`date` with format `uuuu-MM` (ES7 and above)
 or `yyyy-MM\|\|yyyyyyyyy-MM` (ES6 and below)
 |<<backend-elasticsearch-field-types-date-time>>
|java.time.MonthDay
 |`date` with format `uuuu-MM-dd` (ES7 and above)
 or `yyyy-MM-dd` (ES6 and below).
 **The year is always set to 0**.
 |-
|org.hibernate.search.engine.spatial.GeoPoint
 |`geo_point`
 |-
|====

[[backend-elasticsearch-field-types-date-time,Lower range/resolution]]
[NOTE]
.Range and resolution of date/time fields
====
The Elasticsearch `date` type does not support the whole range of years that can be represented in `java.time` types:

* `java.time` can represent years ranging from `-999.999.999` to `999.999.999`.
* Elasticsearch's `date` type supports dates ranging from year `-292.275.054` to year `292.278.993`.

Values that are out of range will trigger indexing failures.

Resolution is also lower:

* `java.time` supports nanosecond-resolution.
* Elasticsearch's `date` type supports millisecond-resolution.

Precision beyond the millisecond will be lost when indexing.
====

[[backend-elasticsearch-field-types-extension]]
==== Index field type DSL extension

Not all Elasticsearch field types have built-in support in Hibernate Search.
Unsupported field types can still be used, however,
by taking advantage of the "native" field type.
Using this field type, the Elasticsearch "mapping" can be defined as JSON directly,
giving access to everything Elasticsearch can offer.

Below is an example of how to use the Elasticearch "native" type.

.Using the Elasticearch "native" type
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/backend/elasticsearch/type/asnative/IpAddressValueBinder.java[tags=include]
----
<1> Define a <<mapper-orm-bridge,custom binder>> and its bridge.
The "native" type can only be used from a binder,
it cannot be used directly with annotation mapping.
Here we're defining a <<mapper-orm-bridge-valuebridge,value binder>>,
but a <<mapper-orm-bridge-typebridge,type binder>>,
or a <<mapper-orm-bridge-propertybridge,property binder>>
would work as well.
<2> Get the context's type factory.
<3> Apply the Elasticsearch extension to the type factory.
<4> Call `asNative` to start defining a native type.
<5> Pass the Elasticsearch mapping as JSON.
<6> Values of native fields are represented as a `JsonElement` in Hibernate Search.
`JsonElement` is a type from the link:{gsonUrl}[Gson] library.
Do not forget to format them correctly before you pass them to the backend.
Here we are creating a `JsonPrimitive` (a subtype of `JsonElement`) from a `String`
because we just need a JSON string,
but it's completely possible to handle more complex objects,
or even to convert directly from POJOs to JSON using Gson.
<7> For nicer projections, you can also implement this method to convert
from `JsonElement` to the mapped type (here, `String`).

[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/backend/elasticsearch/type/asnative/CompanyServer.java[tags=include;!getters-setters]
----
<1> Map the property to an index field.
Note that value bridges using a non-standard type (such as Elasticsearch's "native" type)
must be mapped using the `@NonStandardField` annotation:
other annotations such as `@GenericField` will fail.
<2> Instruct Hibernate Search to use our custom value binder.
====

[[backend-elasticsearch-type-name]]
=== Type name mapping

When Hibernate Search performs a search query targeting multiple entity types, and thus multiple indexes,
it needs to determine the type of each search hit in order to map it back to an entity.

There are multiple strategies to handle this "type name resolution",
and each has pros and cons.

The strategy is set a the backend level:

[source]
----
hibernate.search.backends.<backend-name>.mapping.type_name.strategy = discriminator (default)
----

See the following subsections for details about available strategies.

[[backend-elasticsearch-type-name-discriminator]]
==== `discriminator`: type name mapping using a discriminator field

With the `discriminator` strategy, a discriminator field is used to retrieve the type name directly from each document.

When indexing, the `_entity_type` field is populated transparently with type name for each document.

When searching, the docvalues for the type field is transparently requested to Elasticsearch
and extracted from the response.

Pros:

* Works correctly when targeting link:{elasticsearchDocUrl}/indices-add-alias.html[index aliases].

Cons:

* Small storage overhead: a few bytes of storage per document.
* Requires reindexing if an entity name changes, even if the index name doesn't change.

[[backend-elasticsearch-type-name-index-name]]
==== `index-name`: type name mapping using the index name

With the `index-name` strategy, the `_index` meta-field returned for each search hit
is used to resolve the index name, and from that the type name.

Pros:

* No storage overhead.

Cons:

* Relies on the actual index name, not aliases,
because the `_index` meta-field returned by Elasticsearch
contains the actual index name (e.g. `myindex-000001`), not the alias (e.g. `myindex-read`).
If indexes do not follow the default naming scheme `<hibernateSearchIndexName>-<6 digits>`,
a custom <<backend-elasticsearch-indexlayout,index layout>> must be configured.

[[backend-elasticsearch-multi-tenancy]]
=== Multi-tenancy

Multi-tenancy is supported and handled transparently,
according to the tenant ID defined in the current session:

* documents will be indexed with the appropriate values, allowing later filtering;
* queries will filter results appropriately.

However, a strategy must be selected in order to enable multi-tenancy.

The multi-tenancy strategy is set a the backend level:

[source]
----
hibernate.search.backends.<backend name>.multi_tenancy.strategy = none (default)
----

See the following subsections for details about available strategies.

[[backend-elasticsearch-multi-tenancy-none]]
==== `none`: single-tenancy

The `none` strategy (the default) disables multi-tenancy completely.

Attempting to set a tenant ID will lead to a failure when indexing.

[[backend-elasticsearch-multi-tenancy-discriminator]]
==== `discriminator`: type name mapping using the index name

With the `discriminator` strategy,
all documents from all tenants are stored in the same index.
The Elasticsearch ID of each document is set to the concatenation of the tenant ID and original ID.

When indexing, two fields are populated transparently for each document:

* `_tenant_id`: the "discriminator" field holding the tenant ID.
* `_tenant_doc_id`: a field holding the the original (tenant-scoped) document ID.

When searching, a filter targeting the tenant ID field is added transparently to the search query
to only return search hits for the current tenant.
The ID field is used to retrieve the original document IDs.

[[backend-elasticsearch-analysis]]
== Analysis
// Search 5 anchors backward compatibility
[[elasticsearch-mapping-analyzer]]

<<concepts-analysis,Analysis>> is the text processing performed by analyzers,
both when indexing (document processing)
and when searching (query processing).

All built-in Elasticsearch analyzers can be used transparently,
without any configuration in Hibernate Search:
just use their name wherever Hibernate Search expects an analyzer name.
However, in order to define custom analyzers,
analysis must be configured explicitly.

[CAUTION]
====
Elasticsearch analysis configuration is not applied immediately on startup:
it needs to be pushed to the Elasticsearch cluster.
Hibernate Search will only push the configuration to the cluster if specific conditions are met,
and only if instructed to do so
through the <<backend-elasticsearch-index-lifecycle,lifecycle configuration>>.
====

To configure analysis in an Elasticsearch backend, you will need to:

* Define a class that implements the `org.hibernate.search.backend.elasticsearch.analysis.ElasticsearchAnalysisConfigurer` interface.
* Configure the backend to use that implementation by setting the configuration property
`hibernate.search.backends.<backend name>.analysis.configurer`
to a <<configuration-property-types,bean reference>> pointing to the implementation.

Hibernate Search will call the `configure` method of this implementation on startup,
and the configurer will be able to take advantage of a DSL to define analyzers:

.Implementing and using an analysis configurer with the Elasticsearch backend
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/analysis/MyElasticsearchAnalysisConfigurer.java[tags=include]
----
<1> Define a custom analyzer named "english", because it will be used to analyze English text such as book titles.
<2> Set the tokenizer to a standard tokenizer.
<3> Set the char filters. Char filters are applied in the order they are given, before the tokenizer.
<4> Set the token filters. Token filters are applied in the order they are given, after the tokenizer.
<5> Note that, for Elasticsearch, any parameterized char filter, tokenizer or token filter
must be defined separately and assigned a name.
<6> Set the value of a parameter for the char filter/tokenizer/token filter being defined.
<7> Normalizers are defined in a similar way, the only difference being that they cannot use a tokenizer.
<8> Multiple analyzers/normalizers can be defined in the same configurer.

[source, XML, indent=0, subs="+callouts"]
----
include::{resourcesdir}/analysis/elasticsearch-simple.properties[]
----
<1> Assign the configurer to the backend `myBackend` using a Hibernate Search configuration property.
====

It is also possible to assign a name to a parameterized built-in analyzer:

.Naming a parameterized built-in analyzer in the Elasticsearch backend
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/analysis/AdvancedElasticsearchAnalysisConfigurer.java[tags=type]
----
<1> Define an analyzer with the given name and type.
<2> Set the value of a parameter for the analyzer being defined.
====

[TIP]
====
To know which character filters, tokenizers and token filters are available,
refer to the documentation:

* If you want to use a built-in analyzer and not create your own:
{elasticsearchDocUrl}/analysis-analyzers.html[analyzers];
* If you want to define your own analyzer:
{elasticsearchDocUrl}/analysis-charfilters.html[character filters],
{elasticsearchDocUrl}/analysis-tokenizers.html[tokenizers],
{elasticsearchDocUrl}/analysis-tokenfilters.html[token filters].
====

[[backend-elasticsearch-threads]]
== Threads

The Elasticsearch backend relies on an internal thread pool to orchestrate indexing requests (add/update/delete)
and to schedule request timeouts.

By default, the pool contains exactly as many threads as the number of processors available to the JVM on bootstrap.
That can be changed using a configuration property:

[source]
----
hibernate.search.backends.<backend-name>.thread_pool.size = 4
----

[NOTE]
====
This number is _per backend_, not per index.
Adding more indexes will not add more threads.
====

[TIP]
====
As all operations happening in this thread-pool are non-blocking,
raising its size above the number of processor cores available to the JVM will not bring
noticeable performance benefits.

The only reason to alter this setting would be to reduce the number of threads;
for example, in an application with a single index with a single indexing queue,
running on a machine with 64 processor cores,
you might want to bring down the number of threads.
====

[[backend-elasticsearch-indexing-queues]]
== Indexing queues

Among all the requests sent by Hibernate Search to Elasticsearch,
it is expected that there will be a lot of "indexing" requests to create/update/delete a specific document.
Sending these requests one by one would be inefficient (mainly because of network latency).
Also, we generally want to preserve the relative order of these requests
when they are about the same documents.

For these reasons, Hibernate Search pushes these requests to ordered queues
and relies on the link:{elasticsearchDocUrl}/docs-bulk.html[Bulk API] to send them in batches.
Each index maintains 10 queues holding at most 1000 elements each,
and each queue will send bulk requests of at most 100 indexing requests.
Queues operate independently (in parallel), but each queue sends one bulk request after the other,
so at any given time there can be at most 10 bulk requests being sent for each index.

[NOTE]
====
Indexing operations relative to the same document ID are always pushed to the same queue.
====

It is possible to customize the queues in order to reduce the load on the Elasticsearch server,
or on the contrary to improve throughput.
This is done through the following configuration properties, at the index level:

[source]
----
hibernate.search.backends.<backend name>.indexes.<index name>.indexing.queue_count 10 (default)
hibernate.search.backends.<backend name>.indexes.<index name>.indexing.queue_size 1000 (default)
hibernate.search.backends.<backend name>.indexes.<index name>.indexing.max_bulk_size 100 (default)
# OR
hibernate.search.backends.<backend name>.index_defaults.indexing.queue_count 10 (default)
hibernate.search.backends.<backend name>.index_defaults.indexing.queue_size 1000 (default)
hibernate.search.backends.<backend name>.index_defaults.indexing.max_bulk_size 100 (default)
----

* `indexing.queue_count` defines the number of queues.
Expects a strictly positive integer value.
+
Higher values will lead to more connections being used in parallel,
which may lead to higher indexing throughput,
but incurs a risk of <<backend-elasticsearch-indexing-queues-circuit-breaker,overloading Elasticsearch>>,
leading to Elasticsearch giving up on some requests and resulting in indexing failures.
* `indexing.queue_size` defines the maximum number of elements each queue can hold.
Expects a strictly positive integer value.
+
Lower values may lead to lower memory usage, especially if there are many queues,
but values that are too low will reduce the likeliness of reaching the max bulk size
and increase the likeliness of <<backend-elasticsearch-indexing-queues-blocking,application threads blocking>>
because the queue is full,
which may lead to lower indexing throughput.
* `indexing.max_bulk_size` defines the maximum number of indexing requests in each bulk request.
Expects a strictly positive integer value.
+
Higher values will lead to more documents being sent in each HTTP request sent to Elasticsearch,
which may lead to higher indexing throughput,
but incurs a risk of <<backend-elasticsearch-indexing-queues-circuit-breaker,overloading Elasticsearch>>,
leading to Elasticsearch giving up on some requests and resulting in indexing failures.
+
Note that raising this number above the queue size has no effect,
as bulks cannot include more requests than are contained in the queue.

[TIP]
[[backend-elasticsearch-indexing-queues-blocking]]
====
When a queue is full, any attempt to request indexing will block until the request can be put into the queue.

In order to achieve a reasonable level of performance,
be sure to set the size of queues to a high enough number that this kind of blocking only happens
when the application is under very high load.
====

[WARNING]
[[backend-elasticsearch-indexing-queues-circuit-breaker]]
====
Elasticsearch nodes can only handle so many parallel requests,
and in particular they link:{elasticsearchDocUrl}/circuit-breaker.html[limit the amount of memory]
available to store all pending requests at any given time.

In order to avoid indexing failures, avoid using overly large numbers
for the number of queues and the maximum bulk size,
especially if you expect your index to hold large documents.
====

[[backend-elasticsearch-io]]
== Writing and reading

include::components/writing-reading-intro-note.asciidoc[]

[[backend-elasticsearch-io-commit]]
=== Commit

When writing to indexes, Elasticsearch relies on a link:{elasticsearchDocUrl}/index-modules-translog.html[transaction log]
to make sure that changes, even uncommitted, are always safe as soon as the REST API call returns.

For that reason, the concept of "commit" is not as important to the Elasticsearch backend,
and commit requirements are largely irrelevant.

[[backend-elasticsearch-io-refresh]]
=== Refresh

When reading from indexes, Elasticsearch relies on a periodically refreshed index reader,
meaning that search queries will return slightly out-of-date results,
unless a refresh was forced:
this is called link:{elasticsearchDocUrl}/getting-started-concepts.html#_near_realtime_nrt[near-real-time] behavior.

By default, the index reader is refreshed every second,
but this can be customized on the Elasticsearch side through index settings:
see the `refresh_interval` setting on link:{elasticsearchDocUrl}/index-modules.html[this page].

[[backend-elasticsearch-access-client]]
== Retrieving the REST client
// Search 5 anchors backward compatibility
[[elasticsearch-client-access]]

When writing complex applications with advanced requirements,
it may be necessary from time to time to send requests to the Elasticsearch cluster directly,
in particular if Hibernate Search does not support this kind of requests out of the box.

To that end, you can retrieve the Elasticsearch backend,
then get access the Elasticsearch client used by Hibernate Search internally.
See below for an example.

.Accessing the low-level REST client
====
[source, JAVA, indent=0, subs="+callouts"]
----
include::{sourcedir}/org/hibernate/search/documentation/backend/elasticsearch/client/ElasticsearchGetClientIT.java[tags=client]
----
<1> Retrieve the `SearchMapping`.
<2> Retrieve the `Backend`.
<3> Narrow down the backend to the `ElasticsearchBackend` type.
<4> Get the client, passing the expected type of the client as an argument.
====

[WARNING]
====
The client itself is not part of the Hibernate Search API,
but of the
link:{elasticsearchDocUrl}/index-modules.html#_static_index_settings[official Elasticsearch REST client API].

Hibernate Search may one day switch to another client with a different Java type,
without prior notice.
If that happens, the snippet of code above will throw an exception.
====
