<?xml version="1.0" encoding="UTF-8"?>
<!--
 ~ Hibernate Search, full-text search for your domain model
 ~
 ~ License: GNU Lesser General Public License (LGPL), version 2.1 or later
 ~ See the lgpl.txt file in the root directory or <http://www.gnu.org/licenses/lgpl-2.1.html>.
  -->
<job id="BatchIndexingJob" xmlns="http://xmlns.jcp.org/xml/ns/javaee" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xsi:schemaLocation="http://xmlns.jcp.org/xml/ns/javaee http://xmlns.jcp.org/xml/ns/javaee/jobXML_1_0.xsd" version="1.0">

    <listeners>
        <!--
            The following batch artifact is designed to be overridden when using dependency injection.
            To do so, the overriding bean must extends JobContextSetupListener and its name
            in the dependency injection context must be the fully-qualified class name of
            JobContextSetupListener.
            This allows this batch job definition to work even when there is no support for DI.
         -->
        <listener ref="org.hibernate.search.jsr352.massindexing.JobContextSetupListener">
            <properties>
                <property name="entityManagerFactoryScope" value="#{jobParameters['entityManagerFactoryScope']}" />
                <property name="entityManagerFactoryReference" value="#{jobParameters['entityManagerFactoryReference']}" />
                <property name="rootEntities" value="#{jobParameters['rootEntities']}" />
                <property name="criteria" value="#{jobParameters['criteria']}" />
            </properties>
        </listener>
    </listeners>

    <step id="beforeChunk" next="produceLuceneDoc">
        <batchlet ref="org.hibernate.search.jsr352.massindexing.impl.steps.beforechunk.BeforeChunkBatchlet">
            <properties>
                <property name="optimizeAfterPurge" value="#{jobParameters['optimizeAfterPurge']}" />
                <property name="purgeAtStart" value="#{jobParameters['purgeAtStart']}" />
            </properties>
        </batchlet>
    </step>

    <step id="produceLuceneDoc" next="afterChunk">
        <listeners>
            <listener ref="org.hibernate.search.jsr352.massindexing.impl.steps.lucene.StepProgressSetupListener">
                <properties>
                    <property name="isJavaSE" value="#{jobParameters['isJavaSE']}" />
                </properties>
            </listener>
        </listeners>
        <chunk checkpoint-policy="custom">
            <reader ref="org.hibernate.search.jsr352.massindexing.impl.steps.lucene.EntityReader">
                <properties>
                    <property name="entityName" value="#{partitionPlan['entityName']}" />
                    <property name="partitionId" value="#{partitionPlan['partitionId']}" />
                    <property name="cacheable" value="#{jobParameters['cacheable']}?:false;" />
                    <property name="fetchSize" value="#{jobParameters['fetchSize']}?:200000;" />
                    <property name="hql" value="#{jobParameters['hql']}" />
                    <property name="isJavaSE" value="#{jobParameters['isJavaSE']}" />
                    <property name="maxResults" value="#{jobParameters['maxResults']}?:10000000;" />
                </properties>
            </reader>
            <processor ref="org.hibernate.search.jsr352.massindexing.impl.steps.lucene.LuceneDocProducer">
                <properties>
                    <property name="entityName" value="#{partitionPlan['entityName']}" />
                    <property name="isJavaSE" value="#{jobParameters['isJavaSE']}?:false;" />
                </properties>
            </processor>
            <writer ref="org.hibernate.search.jsr352.massindexing.impl.steps.lucene.LuceneDocWriter">
                <properties>
                    <property name="entityName" value="#{partitionPlan['entityName']}" />
                    <property name="isJavaSE" value="#{jobParameters['isJavaSE']}?:false;" />
                </properties>
            </writer>
            <checkpoint-algorithm ref="org.hibernate.search.jsr352.massindexing.impl.steps.lucene.CheckpointAlgorithm">
                <properties>
                    <property name="itemCount" value="#{jobParameters['itemCount']}?:200;" />
                </properties>
            </checkpoint-algorithm>
        </chunk>
        <partition>
            <mapper ref="org.hibernate.search.jsr352.massindexing.impl.steps.lucene.PartitionMapper">
                <properties>
                    <property name="fetchSize" value="#{jobParameters['fetchSize']}?:200000;" />
                    <property name="hql" value="#{jobParameters['hql']}" />
                    <property name="isJavaSE" value="#{jobParameters['isJavaSE']}?:false;" />
                    <property name="maxThreads" value="#{jobParameters['threads']}?:8;" />
                    <property name="rowsPerPartition" value="#{jobParameters['rowsPerPartition']}?:0;" />
                </properties>
            </mapper>
            <collector ref="org.hibernate.search.jsr352.massindexing.impl.steps.lucene.ProgressCollector" />
            <analyzer ref="org.hibernate.search.jsr352.massindexing.impl.steps.lucene.ProgressAggregator" />
        </partition>
    </step>

    <step id="afterChunk">
        <batchlet ref="org.hibernate.search.jsr352.massindexing.impl.steps.afterchunk.AfterChunkBatchlet">
            <properties>
                <property name="optimizeAtEnd" value="#{jobParameters['optimizeAtEnd']}" />
            </properties>
        </batchlet>
    </step>
</job>
